{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"baseline.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPPhYT+qI42fZ4mJM5g2+tr"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"RbUtNDek4RVm","executionInfo":{"status":"ok","timestamp":1604897272761,"user_tz":-540,"elapsed":17876,"user":{"displayName":"장영진","photoUrl":"","userId":"16685945690070219700"}},"outputId":"fb6c6cd4-bfbe-45bf-dcb0-3c3b708a90e5","colab":{"base_uri":"https://localhost:8080/"}},"source":["from google.colab import drive\n","drive.mount(\"/gdrive\", force_remount=True)"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"lK7R3r404hWn","executionInfo":{"status":"ok","timestamp":1604897337570,"user_tz":-540,"elapsed":16986,"user":{"displayName":"장영진","photoUrl":"","userId":"16685945690070219700"}},"outputId":"bc1e8a15-32a1-4b0c-ab6d-75e7ae4fe545","colab":{"base_uri":"https://localhost:8080/","height":630}},"source":["!pip install pytorch-crf\n","!pip install seqeval==1.0.0"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: pytorch-crf in /usr/local/lib/python3.6/dist-packages (0.7.2)\n","Collecting seqeval==1.0.0\n","  Downloading https://files.pythonhosted.org/packages/75/63/180f7556bfd9b0f89bc853ee46d01a3a611d74798230a930afac6873d15c/seqeval-1.0.0.tar.gz\n","Collecting numpy==1.19.2\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/63/97/af8a92864a04bfa48f1b5c9b1f8bf2ccb2847f24530026f26dd223de4ca0/numpy-1.19.2-cp36-cp36m-manylinux2010_x86_64.whl (14.5MB)\n","\u001b[K     |████████████████████████████████| 14.5MB 235kB/s \n","\u001b[?25hCollecting scikit-learn==0.23.2\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5c/a1/273def87037a7fb010512bbc5901c31cfddfca8080bc63b42b26e3cc55b3/scikit_learn-0.23.2-cp36-cp36m-manylinux1_x86_64.whl (6.8MB)\n","\u001b[K     |████████████████████████████████| 6.8MB 46.6MB/s \n","\u001b[?25hCollecting threadpoolctl>=2.0.0\n","  Downloading https://files.pythonhosted.org/packages/f7/12/ec3f2e203afa394a149911729357aa48affc59c20e2c1c8297a60f33f133/threadpoolctl-2.1.0-py3-none-any.whl\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn==0.23.2->seqeval==1.0.0) (0.17.0)\n","Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.6/dist-packages (from scikit-learn==0.23.2->seqeval==1.0.0) (1.4.1)\n","Building wheels for collected packages: seqeval\n","  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for seqeval: filename=seqeval-1.0.0-cp36-none-any.whl size=14022 sha256=af7601337191f0fe650a8e4d1fd0d060d1327aa01e09b6f6fa563db50a006c24\n","  Stored in directory: /root/.cache/pip/wheels/9e/82/18/6cfa15bb8d49855b0636bd72d12ab43fe9c4da8e8ba3b94db2\n","Successfully built seqeval\n","\u001b[31mERROR: tensorflow 2.3.0 has requirement numpy<1.19.0,>=1.16.0, but you'll have numpy 1.19.2 which is incompatible.\u001b[0m\n","\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n","\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n","Installing collected packages: numpy, threadpoolctl, scikit-learn, seqeval\n","  Found existing installation: numpy 1.18.5\n","    Uninstalling numpy-1.18.5:\n","      Successfully uninstalled numpy-1.18.5\n","  Found existing installation: scikit-learn 0.22.2.post1\n","    Uninstalling scikit-learn-0.22.2.post1:\n","      Successfully uninstalled scikit-learn-0.22.2.post1\n","Successfully installed numpy-1.19.2 scikit-learn-0.23.2 seqeval-1.0.0 threadpoolctl-2.1.0\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["numpy"]}}},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"VE78q61EW4s2","executionInfo":{"status":"ok","timestamp":1604898027114,"user_tz":-540,"elapsed":1357,"user":{"displayName":"장영진","photoUrl":"","userId":"16685945690070219700"}},"outputId":"d8d702f0-da2c-40ab-fffd-aca6847b4972","colab":{"base_uri":"https://localhost:8080/","height":402}},"source":["import os\n","from IPython.display import Image\n","root_dir = \"/gdrive/My Drive/인공지능 실습/해커톤 baseline\"\n","Image(os.path.join(root_dir, \"bi_GRU_crfs_model.PNG\"))"],"execution_count":1,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"No such file or directory: '/gdrive/My Drive/인공지능 실습/해커톤 baseline/bi_GRU_crfs_model.PNG'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m~/School/4-2/ai/homeworks/venv/lib/python3.8/site-packages/IPython/core/display.py\u001b[0m in \u001b[0;36m_data_and_metadata\u001b[0;34m(self, always_both)\u001b[0m\n\u001b[1;32m   1292\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1293\u001b[0;31m             \u001b[0mb64_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb2a_base64\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ascii'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1294\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: a bytes-like object is required, not 'str'","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m~/School/4-2/ai/homeworks/venv/lib/python3.8/site-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj, include, exclude)\u001b[0m\n\u001b[1;32m    968\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    969\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 970\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minclude\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexclude\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    971\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    972\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/School/4-2/ai/homeworks/venv/lib/python3.8/site-packages/IPython/core/display.py\u001b[0m in \u001b[0;36m_repr_mimebundle_\u001b[0;34m(self, include, exclude)\u001b[0m\n\u001b[1;32m   1281\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1282\u001b[0m             \u001b[0mmimetype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mimetype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1283\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_and_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malways_both\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1284\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1285\u001b[0m                 \u001b[0mmetadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mmimetype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/School/4-2/ai/homeworks/venv/lib/python3.8/site-packages/IPython/core/display.py\u001b[0m in \u001b[0;36m_data_and_metadata\u001b[0;34m(self, always_both)\u001b[0m\n\u001b[1;32m   1293\u001b[0m             \u001b[0mb64_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb2a_base64\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ascii'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1294\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1295\u001b[0;31m             raise FileNotFoundError(\n\u001b[0m\u001b[1;32m   1296\u001b[0m                 \"No such file or directory: '%s'\" % (self.data))\n\u001b[1;32m   1297\u001b[0m         \u001b[0mmd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: No such file or directory: '/gdrive/My Drive/인공지능 실습/해커톤 baseline/bi_GRU_crfs_model.PNG'"]}]},{"cell_type":"code","metadata":{"id":"cdBFg0kb4Urd","executionInfo":{"status":"ok","timestamp":1604897378973,"user_tz":-540,"elapsed":4583,"user":{"displayName":"장영진","photoUrl":"","userId":"16685945690070219700"}}},"source":["import torch\n","import torch.nn as nn\n","from torchcrf import CRF\n","\n","from seqeval.metrics import classification_report\n","\n","\n","class RNN_CRF(nn.Module):\n","    def __init__(self, config):\n","        super(RNN_CRF, self).__init__()\n","\n","        # 전체 음절 개수\n","        self.eumjeol_vocab_size = config[\"word_vocab_size\"]\n","\n","        # 음절 임베딩 사이즈\n","        self.embedding_size = config[\"embedding_size\"]\n","\n","        # GRU 히든 사이즈\n","        self.hidden_size = config[\"hidden_size\"]\n","\n","        # 분류할 태그의 개수\n","        self.number_of_tags = config[\"number_of_tags\"]\n","\n","        # 입력 데이터에 있는 각 음절 index를 대응하는 임베딩 벡터로 치환해주기 위한 임베딩 객체\n","        self.embedding = nn.Embedding(num_embeddings=self.eumjeol_vocab_size,\n","                                      embedding_dim=self.embedding_size,\n","                                      padding_idx=0)\n","\n","        self.dropout = nn.Dropout(config[\"dropout\"])\n","\n","        # Bi-GRU layer\n","        self.bi_gru = nn.GRU(input_size = self.embedding_size,\n","                             hidden_size= self.hidden_size,\n","                             num_layers=1,\n","                             batch_first=True,\n","                             bidirectional=True)\n","\n","        # CRF layer\n","        self.crf = CRF(num_tags=self.number_of_tags, batch_first=True)\n","\n","        # fully_connected layer를 통하여 출력 크기를 number_of_tags에 맞춰줌\n","        # (batch_size, max_length, hidden_size*2) -> (batch_size, max_length, number_of_tags)\n","        self.hidden2num_tag = nn.Linear(in_features=self.hidden_size*2, out_features=self.number_of_tags)\n","\n","    def forward(self, inputs, labels=None):\n","        # (batch_size, max_length) -> (batch_size, max_length, embedding_size)\n","        eumjeol_inputs = self.embedding(inputs)\n","\n","        encoder_outputs, hidden_states = self.bi_gru(eumjeol_inputs)\n","\n","        # (batch_size, curr_max_length, hidden_size*2)\n","        d_hidden_outputs = self.dropout(encoder_outputs)\n","\n","        # (batch_size, curr_max_length, hidden_size*2) -> (batch_size, curr_max_length, number_of_tags)\n","        logits = self.hidden2num_tag(d_hidden_outputs)\n","\n","        if(labels is not None):\n","            log_likelihood = self.crf(emissions=logits,\n","                                      tags=labels,\n","                                      reduction=\"mean\")\n","\n","            loss = log_likelihood * -1.0\n","\n","            return loss\n","        else:\n","            output = self.crf.decode(emissions=logits)\n","\n","            return output\n"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"SlVPOWVk4nqP","executionInfo":{"status":"ok","timestamp":1604897383072,"user_tz":-540,"elapsed":686,"user":{"displayName":"장영진","photoUrl":"","userId":"16685945690070219700"}}},"source":["\n","\n","from tqdm import tqdm\n","import numpy as np\n","# 파라미터로 입력받은 파일에 저장된 단어 리스트를 딕셔너리 형태로 저장\n","def load_vocab(f_name):\n","    vocab_file = open(os.path.join(root_dir, f_name),'r',encoding='utf8')\n","    print(\"{} vocab file loading...\".format(f_name))\n","\n","    # default 요소가 저장된 딕셔너리 생성\n","    symbol2idx, idx2symbol = {\"<PAD>\":0, \"<UNK>\":1}, {0:\"<PAD>\", 1:\"<UNK>\"}\n","\n","    # 시작 인덱스 번호 저장\n","    index = len(symbol2idx)\n","    for line in tqdm(vocab_file.readlines()):\n","        symbol = line.strip()\n","        symbol2idx[symbol] = index\n","        idx2symbol[index]= symbol\n","        index+=1\n","\n","    return symbol2idx, idx2symbol\n","\n","# 입력 데이터를 고정 길이의 벡터로 표현하기 위한 함수\n","def convert_data2feature(data, symbol2idx, max_length=None):\n","    # 고정 길이의 0 벡터 생성\n","    feature = np.zeros(shape=(max_length), dtype=np.int)\n","    # 입력 문장을 공백 기준으로 split\n","    words = data.split()\n","\n","    for idx, word in enumerate(words[:max_length]):\n","        if word in symbol2idx.keys():\n","            feature[idx] = symbol2idx[word]\n","        else:\n","            feature[idx] = symbol2idx[\"<UNK>\"]\n","    return feature\n","\n","# 파라미터로 입력받은 파일로부터 tensor객체 생성\n","def load_data(config, f_name, word2idx, tag2idx):\n","    file = open(os.path.join(root_dir, f_name),'r',encoding='utf8')\n","\n","    # return할 문장/라벨 리스트 생성\n","    indexing_inputs, indexing_tags = [], []\n","\n","    print(\"{} file loading...\".format(f_name))\n","\n","    # 실제 데이터는 아래와 같은 형태를 가짐\n","    # 문장 \\t 태그\n","    # 세 종 대 왕 은 <SP> 조 선 의 <SP> 4 대 <SP> 왕 이 야 \\t B_PS I_PS I_PS I_PS O <SP> B_LC I_LC O <SP> O O <SP> O O O\n","    for line in tqdm(file.readlines()):\n","        try:\n","            id, sentence, tags = line.strip().split('\\t')\n","        except:\n","            id, sentence = line.strip().split('\\t')\n","        input_sentence = convert_data2feature(sentence, word2idx, config[\"max_length\"])\n","        indexing_tag = convert_data2feature(tags, tag2idx, config[\"max_length\"])\n","\n","        indexing_inputs.append(input_sentence)\n","        indexing_tags.append(indexing_tag)\n","    indexing_inputs = torch.tensor(indexing_inputs, dtype=torch.long)\n","    indexing_tags = torch.tensor(indexing_tags, dtype=torch.long)\n","\n","    return indexing_inputs, indexing_tags\n","\n","# tensor 객체를 리스트 형으로 바꾸기 위한 함수\n","def tensor2list(input_tensor):\n","    return input_tensor.cpu().detach().numpy().tolist()\n"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"HfKUI3mH4wqh","executionInfo":{"status":"ok","timestamp":1604897384165,"user_tz":-540,"elapsed":736,"user":{"displayName":"장영진","photoUrl":"","userId":"16685945690070219700"}}},"source":["\n","from torch.utils.data import (DataLoader, TensorDataset)\n","import torch.optim as optim\n","\n","def train(config):\n","    # 모델 객체 생성\n","    model = RNN_CRF(config).cuda()\n","    # 단어 딕셔너리 생성\n","    word2idx, idx2word = load_vocab(config[\"word_vocab_file\"])\n","    tag2idx, idx2tag = load_vocab(config[\"tag_vocab_file\"])\n","\n","    # 데이터 Load\n","    train_input_features, train_tags = load_data(config, config[\"train_file\"], word2idx, tag2idx)\n","    test_input_features, test_tags = load_data(config, config[\"dev_file\"], word2idx, tag2idx)\n","\n","    # 불러온 데이터를 TensorDataset 객체로 변환\n","    train_features = TensorDataset(train_input_features, train_tags)\n","    train_dataloader = DataLoader(train_features, shuffle=True, batch_size=config[\"batch_size\"])\n","\n","    test_features = TensorDataset(test_input_features, test_tags)\n","    test_dataloader = DataLoader(test_features, shuffle=False, batch_size=config[\"batch_size\"])\n","\n","    # 모델을 학습하기위한 optimizer\n","    optimizer = optim.Adam(model.parameters(), lr=0.005)\n","\n","    accuracy_list = []\n","    for epoch in range(config[\"epoch\"]):\n","        model.train()\n","        losses = []\n","        for step, batch in enumerate(train_dataloader):\n","            # .cuda()를 이용하여 메모리에 업로드\n","            batch = tuple(t.cuda() for t in batch)\n","            input_features, labels = batch\n","\n","            # loss 계산\n","            loss = model.forward(input_features, labels)\n","\n","            # 변화도 초기화\n","            optimizer.zero_grad()\n","\n","            # loss 값으로부터 모델 내부 각 매개변수에 대하여 gradient 계산\n","            loss.backward()\n","\n","            # 모델 내부 각 매개변수 가중치 갱신\n","            optimizer.step()\n","\n","            if (step + 1) % 50 == 0:\n","                print(\"{} step processed.. current loss : {}\".format(step + 1, loss.data.item()))\n","            losses.append(loss.data.item())\n","\n","\n","\n","        print(\"Average Loss : {}\".format(np.mean(losses)))\n","\n","        # 모델 저장\n","        torch.save(model.state_dict(), os.path.join(config[\"output_dir_path\"], \"epoch_{}.pt\".format(epoch + 1)))\n","\n","        do_test(model, test_dataloader, idx2tag)\n","\n","\n","\n","def test(config):\n","    # 모델 객체 생성\n","    model = RNN_CRF(config).cuda()\n","    # 단어 딕셔너리 생성\n","    word2idx, idx2word = load_vocab(config[\"word_vocab_file\"])\n","    tag2idx, idx2tag = load_vocab(config[\"tag_vocab_file\"])\n","\n","\n","    # 저장된 가중치 Load\n","    model.load_state_dict(torch.load(os.path.join(config[\"output_dir_path\"], config[\"trained_model_name\"])))\n","\n","    # 데이터 Load\n","    test_input_features, test_tags = load_data(config, config[\"dev_file\"], word2idx, tag2idx)\n","\n","    # 불러온 데이터를 TensorDataset 객체로 변환\n","    test_features = TensorDataset(test_input_features, test_tags)\n","    test_dataloader = DataLoader(test_features, shuffle=False, batch_size=config[\"batch_size\"])\n","    # 평가 함수 호출\n","    do_test(model, test_dataloader, idx2tag)\n","\n","def do_test(model, test_dataloader, idx2tag):\n","    model.eval()\n","    predicts, answers = [], []\n","    for step, batch in enumerate(test_dataloader):\n","        # .cuda() 함수를 이용하요 메모리에 업로드\n","        batch = tuple(t.cuda() for t in batch)\n","\n","        # 데이터를 각 변수에 저장\n","        input_features, labels = batch\n","\n","        # 예측 라벨 출력\n","        output = model(input_features)\n","\n","        # 성능 평가를 위해 예측 값과 정답 값 리스트에 저장\n","        for idx, answer in enumerate(tensor2list(labels)):\n","            answers.extend([idx2tag[e].replace(\"_\", \"-\") for e in answer if idx2tag[e] != \"<SP>\" and idx2tag[e] != \"<PAD>\"])\n","            predicts.extend([idx2tag[e].replace(\"_\", \"-\") for i, e in enumerate(output[idx]) if idx2tag[answer[i]] != \"<SP>\" and idx2tag[answer[i]] != \"<PAD>\"] )\n","    \n","    # 성능 평가\n","    print(classification_report(answers, predicts))\n"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"QXHsFV-z4zZc","executionInfo":{"status":"ok","timestamp":1604897797665,"user_tz":-540,"elapsed":413138,"user":{"displayName":"장영진","photoUrl":"","userId":"16685945690070219700"}},"outputId":"8ea46d28-a59d-4e53-e1f7-088a9d24562c","colab":{"base_uri":"https://localhost:8080/"}},"source":["##########################################################\n","#                                                        #\n","#        평가 기준이 되는 지표는 Macro F1 Score                #\n","#           제출 포맷은 id \\t predict_tag                   #\n","#            25 \\t B_PS I_PS <SP> O O O ...              #\n","#                                                        #\n","##########################################################\n","\n","\n","import os\n","if(__name__==\"__main__\"):\n","    output_dir = os.path.join(root_dir, \"output\")\n","    if not os.path.exists(output_dir):\n","        os.makedirs(output_dir)\n","\n","    config = {\"mode\": \"train\",\n","              \"train_file\":\"ner_train.txt\",\n","              \"dev_file\": \"ner_dev.txt\",\n","              \"word_vocab_file\":\"vocab.txt\",\n","              \"tag_vocab_file\":\"tag_vocab.txt\",\n","              \"trained_model_name\":\"epoch_{}.pt\".format(5),\n","              \"output_dir_path\":output_dir,\n","              \"word_vocab_size\":2160,\n","              \"number_of_tags\": 14,\n","              \"hidden_size\": 100,\n","              \"dropout\":0.2,\n","              \"embedding_size\":100,\n","              \"max_length\": 120,\n","              \"batch_size\":64,\n","              \"epoch\":20,\n","              }\n","\n","    if(config[\"mode\"] == \"train\"):\n","        train(config)\n","    else:\n","        test(config)\n"],"execution_count":7,"outputs":[{"output_type":"stream","text":["vocab.txt vocab file loading...\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 2158/2158 [00:00<00:00, 574832.21it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["tag_vocab.txt vocab file loading...\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 12/12 [00:00<00:00, 3881.82it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["ner_train.txt file loading...\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 7319/7319 [00:00<00:00, 21803.16it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["ner_dev.txt file loading...\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 995/995 [00:00<00:00, 23381.72it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["50 step processed.. current loss : 17.679113388061523\n","100 step processed.. current loss : 14.059734344482422\n","Average Loss : 34.71962947845459\n","49958\n","49958\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/seqeval/metrics/sequence_labeling.py:45: UserWarning: <PAD> seems not to be NE tag.\n","  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n"],"name":"stderr"},{"output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","          DT       0.59      0.60      0.60       609\n","          LC       0.60      0.41      0.49       534\n","          OG       0.47      0.23      0.31       963\n","          PS       0.58      0.33      0.42       733\n","          TI       0.41      0.28      0.33        94\n","\n","   micro avg       0.55      0.37      0.44      2933\n","   macro avg       0.53      0.37      0.43      2933\n","weighted avg       0.54      0.37      0.43      2933\n","\n","50 step processed.. current loss : 12.448100090026855\n","100 step processed.. current loss : 8.960395812988281\n","Average Loss : 11.06712414285411\n","49958\n","49958\n","              precision    recall  f1-score   support\n","\n","          DT       0.77      0.63      0.69       609\n","          LC       0.73      0.51      0.60       534\n","          OG       0.64      0.41      0.50       963\n","          PS       0.57      0.54      0.56       733\n","          TI       0.73      0.55      0.63        94\n","\n","   micro avg       0.66      0.51      0.57      2933\n","   macro avg       0.69      0.53      0.60      2933\n","weighted avg       0.67      0.51      0.58      2933\n","\n","50 step processed.. current loss : 7.885106086730957\n","100 step processed.. current loss : 7.754820823669434\n","Average Loss : 7.71714914156043\n","49958\n","49958\n","              precision    recall  f1-score   support\n","\n","          DT       0.77      0.71      0.74       609\n","          LC       0.66      0.63      0.64       534\n","          OG       0.67      0.52      0.58       963\n","          PS       0.70      0.59      0.64       733\n","          TI       0.75      0.67      0.71        94\n","\n","   micro avg       0.69      0.60      0.64      2933\n","   macro avg       0.71      0.62      0.66      2933\n","weighted avg       0.70      0.60      0.64      2933\n","\n","50 step processed.. current loss : 5.970104217529297\n","100 step processed.. current loss : 6.087859153747559\n","Average Loss : 6.020648782149605\n","49958\n","49958\n","              precision    recall  f1-score   support\n","\n","          DT       0.79      0.69      0.74       609\n","          LC       0.72      0.60      0.65       534\n","          OG       0.68      0.53      0.60       963\n","          PS       0.75      0.57      0.65       733\n","          TI       0.78      0.66      0.72        94\n","\n","   micro avg       0.73      0.59      0.65      2933\n","   macro avg       0.74      0.61      0.67      2933\n","weighted avg       0.73      0.59      0.65      2933\n","\n","50 step processed.. current loss : 4.669581413269043\n","100 step processed.. current loss : 5.3518524169921875\n","Average Loss : 4.925926784847094\n","49958\n","49958\n","              precision    recall  f1-score   support\n","\n","          DT       0.79      0.71      0.75       609\n","          LC       0.71      0.60      0.65       534\n","          OG       0.68      0.57      0.62       963\n","          PS       0.67      0.66      0.66       733\n","          TI       0.80      0.68      0.74        94\n","\n","   micro avg       0.70      0.63      0.66      2933\n","   macro avg       0.73      0.64      0.68      2933\n","weighted avg       0.71      0.63      0.67      2933\n","\n","50 step processed.. current loss : 5.339784622192383\n","100 step processed.. current loss : 6.128003120422363\n","Average Loss : 4.028546917956809\n","49958\n","49958\n","              precision    recall  f1-score   support\n","\n","          DT       0.77      0.73      0.75       609\n","          LC       0.70      0.65      0.67       534\n","          OG       0.72      0.54      0.61       963\n","          PS       0.69      0.64      0.67       733\n","          TI       0.74      0.68      0.71        94\n","\n","   micro avg       0.72      0.63      0.67      2933\n","   macro avg       0.73      0.65      0.68      2933\n","weighted avg       0.72      0.63      0.67      2933\n","\n","50 step processed.. current loss : 3.6620893478393555\n","100 step processed.. current loss : 4.232342720031738\n","Average Loss : 3.4477016697759213\n","49958\n","49958\n","              precision    recall  f1-score   support\n","\n","          DT       0.80      0.70      0.75       609\n","          LC       0.74      0.65      0.69       534\n","          OG       0.73      0.52      0.61       963\n","          PS       0.70      0.63      0.66       733\n","          TI       0.76      0.69      0.73        94\n","\n","   micro avg       0.74      0.61      0.67      2933\n","   macro avg       0.75      0.64      0.69      2933\n","weighted avg       0.74      0.61      0.67      2933\n","\n","50 step processed.. current loss : 2.299530029296875\n","100 step processed.. current loss : 2.9640941619873047\n","Average Loss : 2.978153025585672\n","49958\n","49958\n","              precision    recall  f1-score   support\n","\n","          DT       0.78      0.73      0.75       609\n","          LC       0.76      0.61      0.68       534\n","          OG       0.70      0.60      0.64       963\n","          PS       0.68      0.66      0.67       733\n","          TI       0.73      0.68      0.70        94\n","\n","   micro avg       0.72      0.65      0.68      2933\n","   macro avg       0.73      0.66      0.69      2933\n","weighted avg       0.72      0.65      0.68      2933\n","\n","50 step processed.. current loss : 2.1247987747192383\n","100 step processed.. current loss : 3.2392711639404297\n","Average Loss : 2.4990473280782286\n","49958\n","49958\n","              precision    recall  f1-score   support\n","\n","          DT       0.78      0.72      0.75       609\n","          LC       0.74      0.64      0.69       534\n","          OG       0.69      0.59      0.64       963\n","          PS       0.69      0.67      0.68       733\n","          TI       0.76      0.68      0.72        94\n","\n","   micro avg       0.72      0.65      0.68      2933\n","   macro avg       0.73      0.66      0.70      2933\n","weighted avg       0.72      0.65      0.68      2933\n","\n","50 step processed.. current loss : 2.4493322372436523\n","100 step processed.. current loss : 2.8649425506591797\n","Average Loss : 2.1700164214424467\n","49958\n","49958\n","              precision    recall  f1-score   support\n","\n","          DT       0.80      0.72      0.76       609\n","          LC       0.73      0.63      0.68       534\n","          OG       0.68      0.60      0.64       963\n","          PS       0.70      0.66      0.68       733\n","          TI       0.76      0.68      0.72        94\n","\n","   micro avg       0.72      0.65      0.68      2933\n","   macro avg       0.74      0.66      0.69      2933\n","weighted avg       0.72      0.65      0.68      2933\n","\n","50 step processed.. current loss : 1.5564041137695312\n","100 step processed.. current loss : 2.5895185470581055\n","Average Loss : 1.9893333041149637\n","49958\n","49958\n","              precision    recall  f1-score   support\n","\n","          DT       0.78      0.71      0.74       609\n","          LC       0.74      0.60      0.67       534\n","          OG       0.72      0.59      0.65       963\n","          PS       0.74      0.65      0.69       733\n","          TI       0.81      0.71      0.76        94\n","\n","   micro avg       0.74      0.63      0.68      2933\n","   macro avg       0.76      0.65      0.70      2933\n","weighted avg       0.75      0.63      0.68      2933\n","\n","50 step processed.. current loss : 1.3788042068481445\n","100 step processed.. current loss : 2.4917774200439453\n","Average Loss : 1.7428549434827723\n","49958\n","49958\n","              precision    recall  f1-score   support\n","\n","          DT       0.76      0.73      0.74       609\n","          LC       0.72      0.64      0.68       534\n","          OG       0.67      0.60      0.64       963\n","          PS       0.76      0.64      0.70       733\n","          TI       0.73      0.62      0.67        94\n","\n","   micro avg       0.72      0.65      0.68      2933\n","   macro avg       0.73      0.65      0.68      2933\n","weighted avg       0.72      0.65      0.68      2933\n","\n","50 step processed.. current loss : 1.4826173782348633\n","100 step processed.. current loss : 0.892115592956543\n","Average Loss : 1.5953431087991465\n","49958\n","49958\n","              precision    recall  f1-score   support\n","\n","          DT       0.77      0.72      0.74       609\n","          LC       0.71      0.63      0.67       534\n","          OG       0.69      0.60      0.64       963\n","          PS       0.70      0.67      0.68       733\n","          TI       0.76      0.67      0.71        94\n","\n","   micro avg       0.71      0.65      0.68      2933\n","   macro avg       0.73      0.66      0.69      2933\n","weighted avg       0.71      0.65      0.68      2933\n","\n","50 step processed.. current loss : 1.3337888717651367\n","100 step processed.. current loss : 1.810098648071289\n","Average Loss : 1.487918266006138\n","49958\n","49958\n","              precision    recall  f1-score   support\n","\n","          DT       0.73      0.71      0.72       609\n","          LC       0.69      0.65      0.67       534\n","          OG       0.69      0.57      0.62       963\n","          PS       0.62      0.68      0.65       733\n","          TI       0.71      0.68      0.70        94\n","\n","   micro avg       0.68      0.64      0.66      2933\n","   macro avg       0.69      0.66      0.67      2933\n","weighted avg       0.68      0.64      0.66      2933\n","\n","50 step processed.. current loss : 1.488480567932129\n","100 step processed.. current loss : 1.4474992752075195\n","Average Loss : 1.3945122293804002\n","49958\n","49958\n","              precision    recall  f1-score   support\n","\n","          DT       0.74      0.70      0.72       609\n","          LC       0.65      0.66      0.65       534\n","          OG       0.64      0.60      0.62       963\n","          PS       0.70      0.65      0.68       733\n","          TI       0.77      0.65      0.71        94\n","\n","   micro avg       0.68      0.65      0.66      2933\n","   macro avg       0.70      0.65      0.68      2933\n","weighted avg       0.68      0.65      0.66      2933\n","\n","50 step processed.. current loss : 1.4192075729370117\n","100 step processed.. current loss : 1.561086654663086\n","Average Loss : 1.2718892864559008\n","49958\n","49958\n","              precision    recall  f1-score   support\n","\n","          DT       0.78      0.74      0.76       609\n","          LC       0.73      0.61      0.66       534\n","          OG       0.67      0.60      0.63       963\n","          PS       0.65      0.68      0.67       733\n","          TI       0.80      0.72      0.76        94\n","\n","   micro avg       0.70      0.65      0.68      2933\n","   macro avg       0.73      0.67      0.70      2933\n","weighted avg       0.70      0.65      0.68      2933\n","\n","50 step processed.. current loss : 0.8610086441040039\n","100 step processed.. current loss : 1.3999805450439453\n","Average Loss : 1.1286320074744847\n","49958\n","49958\n","              precision    recall  f1-score   support\n","\n","          DT       0.78      0.73      0.75       609\n","          LC       0.75      0.62      0.68       534\n","          OG       0.69      0.57      0.63       963\n","          PS       0.69      0.65      0.67       733\n","          TI       0.76      0.68      0.72        94\n","\n","   micro avg       0.72      0.64      0.68      2933\n","   macro avg       0.73      0.65      0.69      2933\n","weighted avg       0.72      0.64      0.68      2933\n","\n","50 step processed.. current loss : 0.6632547378540039\n","100 step processed.. current loss : 1.0878229141235352\n","Average Loss : 1.0646674840346626\n","49958\n","49958\n","              precision    recall  f1-score   support\n","\n","          DT       0.77      0.71      0.74       609\n","          LC       0.78      0.59      0.67       534\n","          OG       0.70      0.56      0.62       963\n","          PS       0.71      0.66      0.68       733\n","          TI       0.74      0.65      0.69        94\n","\n","   micro avg       0.73      0.62      0.67      2933\n","   macro avg       0.74      0.63      0.68      2933\n","weighted avg       0.73      0.62      0.67      2933\n","\n","50 step processed.. current loss : 1.1511850357055664\n","100 step processed.. current loss : 0.6871852874755859\n","Average Loss : 1.0619032538455466\n","49958\n","49958\n","              precision    recall  f1-score   support\n","\n","          DT       0.77      0.74      0.75       609\n","          LC       0.72      0.63      0.67       534\n","          OG       0.71      0.54      0.61       963\n","          PS       0.67      0.67      0.67       733\n","          TI       0.77      0.73      0.75        94\n","\n","   micro avg       0.71      0.64      0.67      2933\n","   macro avg       0.73      0.66      0.69      2933\n","weighted avg       0.71      0.64      0.67      2933\n","\n","50 step processed.. current loss : 0.934575080871582\n","100 step processed.. current loss : 1.2572689056396484\n","Average Loss : 1.0217822209648464\n","49958\n","49958\n","              precision    recall  f1-score   support\n","\n","          DT       0.77      0.72      0.74       609\n","          LC       0.71      0.58      0.64       534\n","          OG       0.67      0.58      0.62       963\n","          PS       0.70      0.64      0.67       733\n","          TI       0.73      0.67      0.70        94\n","\n","   micro avg       0.71      0.63      0.67      2933\n","   macro avg       0.72      0.64      0.68      2933\n","weighted avg       0.71      0.63      0.67      2933\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ENjD9mNs5B3U"},"source":[""],"execution_count":null,"outputs":[]}]}