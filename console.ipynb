{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5-final"
    },
    "orig_nbformat": 2,
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "console.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HyunLee103/NER_korean/blob/main/console.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BAazdWu9ongG",
        "outputId": "978bf380-fa86-45a6-ad93-e93616ec5206"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "spklXwDCohhL"
      },
      "source": [
        "## Raw Data 로드"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "jLuGUEobohhL"
      },
      "source": [
        "import os\n",
        "\n",
        "BASE_DIR = '/content/drive/MyDrive/ku-ai/data'\n",
        "\n",
        "def load_data(file_name):\n",
        "    with open(os.path.join(BASE_DIR, file_name), 'r', encoding='utf-8') as fp:\n",
        "        return fp.readlines()\n",
        "\n",
        "raw_train_data = load_data('ner_train.txt')\n",
        "raw_test_data = load_data('ner_dev.txt')"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "U0Zfz_6eohhL",
        "outputId": "c7c115fb-bf1a-4f95-a041-23d60b31a0dc"
      },
      "source": [
        "tmp_data = raw_train_data[0]\n",
        "tmp_data"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'366\\t새 벽 출 조 시 <SP> 야 영 적 극 <SP> 권 장 하 ㅂ 니 다 <SP> .\\tB_TI I_TI O O O <SP> O O O O <SP> O O O O O O <SP> O\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CRMg_Co1ohhM"
      },
      "source": [
        "## Feature 로드\n",
        "\n",
        "```\n",
        "{형태소: 161차원 vector}\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vnjwzVIIohhM",
        "outputId": "b5c61d0d-85ac-4af2-e689-2795b6977701"
      },
      "source": [
        "import joblib\n",
        "\n",
        "train_feature = joblib.load(os.path.join(BASE_DIR, 'train_concat_features'))\n",
        "test_feature = joblib.load(os.path.join(BASE_DIR, 'dev_concat_features'))\n",
        "\n",
        "train_feature['새벽'].shape"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(184,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "YVcwZ8LoohhM"
      },
      "source": [
        "## 통합 데이터셋 만들기\n",
        "\n",
        "```\n",
        "{형태소: 161차원 vector}\n",
        "```\n",
        "\n",
        "Input: 음절단위 문장\n",
        "\n",
        "1. 합친다\n",
        "2. 형태소로짼다\n",
        "3. 아까했던 헝태소: 벡터 를 (길이) 만큼 한다\n",
        "4. 그러면 (seq_len, 161) 의 벡터가 데이터 크기만큼 나온다.\n",
        "5. <SOS\\> 벡터, <EOS\\> 벡터, <PAD\\> 벡터를 준다.\n",
        "6. ?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oKKmVKJzohhN",
        "outputId": "266a82bf-11f6-4a5c-f9b0-f9903e26d4d6"
      },
      "source": [
        "train_morph_token = joblib.load(os.path.join(BASE_DIR, 'train_morph_token'))\n",
        "train_pos_token = joblib.load(os.path.join(BASE_DIR, 'train_pos_token'))\n",
        "\n",
        "test_morph_token = joblib.load(os.path.join(BASE_DIR, 'test_morph_token'))\n",
        "test_pos_token = joblib.load(os.path.join(BASE_DIR, 'test_pos_token'))\n",
        "\n",
        "print(train_morph_token[0])\n",
        "print(train_pos_token[0])\n",
        "print(test_morph_token[0])\n",
        "print(test_pos_token[0])"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['새벽', '출조', '시', '<SP>', '야영', '적극', '<SP>', '권장', '하', 'ㅂ니다', '<SP>', '.']\n",
            "['NNG', 'NNG', 'NNG', '<SP>', 'NNG', 'NNG', '<SP>', 'NNG', 'XSV', 'EF', '<SP>', 'SF']\n",
            "['6', '일', '<SP>', '유통', '업계', '와', '<SP>', '정유', '업계', '에', '<SP>', '따르', '면', '<SP>', '‘', '이마트', '-', 'SK', '’', '<SP>', '간판', '을', '<SP>', '내걸', 'ㄴ', '<SP>', '주유소', '가', '<SP>', '올해', '<SP>', '안', '에', '<SP>', '등장', '하', 'ㄹ', '<SP>', '것', '이', '<SP>', '확실시', '되', '자', '<SP>', '이마트', '와', '<SP>', '경쟁', '관계', '에', '<SP>', '있', '는', '<SP>', '롯데마트', '<SP>', '홈플러스', '<SP>', '등', '<SP>', '다른', '<SP>', '대형', '<SP>', '마트', '도', '<SP>', '매장', '<SP>', '내', '<SP>', '주유소', '<SP>', '설립', '을', '<SP>', '위하', '아', '<SP>', '정유', '사와', '<SP>', '물밑', '에서', '<SP>', '활발', '하', '게', '<SP>', '접촉', '하', '고', '<SP>', '있', '다', '.']\n",
            "['SN', 'NNBC', '<SP>', 'NNG', 'NNG', 'JC', '<SP>', 'NNG', 'NNG', 'JKB', '<SP>', 'VV', 'EC', '<SP>', 'SY', 'NNP', 'SY', 'SL', 'SY', '<SP>', 'NNG', 'JKO', '<SP>', 'VV+ETM', 'NNG', '<SP>', 'NNG', 'JKS', '<SP>', 'NNG', '<SP>', 'NNG', 'JKB', '<SP>', 'NNG', 'XSV', 'JKO', '<SP>', 'NNB', 'JKS', '<SP>', 'NNG', 'XSV', 'EC', '<SP>', 'NNP', 'JKB', '<SP>', 'NNG', 'NNG', 'JKB', '<SP>', 'VA', 'ETM', '<SP>', 'NNP', '<SP>', 'NNP', '<SP>', 'NNG', '<SP>', 'MM', '<SP>', 'NNG', '<SP>', 'NNG', 'JX', '<SP>', 'NNG', '<SP>', 'NP', '<SP>', 'NNG', '<SP>', 'NNG', 'JKO', '<SP>', 'VV', 'EC', '<SP>', 'NNG', 'NNG', '<SP>', 'NNG', 'JKB', '<SP>', 'XR', 'XSA', 'EC', '<SP>', 'NNG', 'XSV', 'EC', '<SP>', 'VA', 'EF', 'SF']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ikg7KRtohhN"
      },
      "source": [
        "## `Dataset` 객체로 만들기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VmEgx-ATohhN"
      },
      "source": [
        "import os\n",
        "\n",
        "def convert_sentence(sentence):\n",
        "    return sentence.replace(' ', '').replace('<SP>', ' ')\n",
        "\n",
        "\n",
        "def load_tag_dict():\n",
        "    fp = open(os.path.join(BASE_DIR, 'tag_vocab.txt'), 'r')\n",
        "    tag_2_idx = {'<UNK>': 0, '<SP>': 1, '<EOS>': 2, '<PAD>': 3}\n",
        "    idx_2_tag = {0: '<UNK>', 1: '<SP>', 2: '<EOS>', 3: '<PAD>'}\n",
        "\n",
        "    index = 2\n",
        "    for line in tqdm(fp.readlines()):\n",
        "        tag = line.strip()\n",
        "        tag_2_idx[tag] = index\n",
        "        idx_2_tag[index] = tag\n",
        "        index += 1\n",
        "\n",
        "    return tag_2_idx, idx_2_tag"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "993rt8SdohhN",
        "outputId": "8ca00d66-0fb5-4d63-e3a3-296d599b2769"
      },
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "UNK_TOKEN = 0\n",
        "SP_TOKEN = 1\n",
        "EOS_TOKEN = 2\n",
        "PAD_TOKEN = 3\n",
        "\n",
        "FEATURE_SIZE = 184\n",
        "\n",
        "UNK_VECTOR = [UNK_TOKEN] * FEATURE_SIZE\n",
        "SP_VECTOR = [SP_TOKEN] * FEATURE_SIZE\n",
        "EOS_VECTOR = [EOS_TOKEN] * FEATURE_SIZE\n",
        "PAD_VECTOR = [PAD_TOKEN] * FEATURE_SIZE\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "\n",
        "class NERDataset(Dataset):\n",
        "    def __init__(self, raw_data, morphs_list, pos_list, feature=None, device='cpu'):\n",
        "        super(NERDataset, self).__init__()\n",
        "        self.source_list = []\n",
        "        self.target_list = []\n",
        "\n",
        "        tag_dict = load_tag_dict()\n",
        "        max_length = self._get_max_length(raw_data)\n",
        "\n",
        "        for row, morphs, pos in tqdm(zip(raw_data, morphs_list, pos_list)):\n",
        "            index, syllables, tags = row.rstrip('\\n').split('\\t')\n",
        "            syllables_list = syllables.split()\n",
        "            tags_list = tags.split()\n",
        "\n",
        "            encoded_syllable_list = []\n",
        "            if feature:\n",
        "                for morph in morphs:\n",
        "                    if morph in feature.keys():\n",
        "                        morph_size = len(morph) if morph != '<SP>' else 1\n",
        "                        encoded_syllable_list += [feature[morph]] * morph_size\n",
        "                    else:\n",
        "                        encoded_syllable_list += [UNK_VECTOR] * len(morph)\n",
        "\n",
        "                padding_size = max_length - len(encoded_syllable_list)\n",
        "                encoded_syllable_list.append(EOS_VECTOR)\n",
        "                encoded_syllable_list += [PAD_VECTOR] * padding_size\n",
        "\n",
        "                self.source_list.append(encoded_syllable_list)\n",
        "            else:\n",
        "                # TODO: raw feature generation\n",
        "                pass\n",
        "\n",
        "            encoded_tag_list = []\n",
        "            for tag in tags_list:\n",
        "                if tag in tag_dict.keys():\n",
        "                    encoded_tag_list.append(tag_dict[tag])\n",
        "                else:\n",
        "                    encoded_tag_list.append(tag_dict['<UNK>'])\n",
        "\n",
        "            padding_size = max_length - len(encoded_tag_list)\n",
        "            encoded_tag_list.append(tag_dict['<EOS>'])\n",
        "            encoded_tag_list += [tag_dict['<PAD>']] * padding_size\n",
        "\n",
        "            self.target_list.append(encoded_tag_list)\n",
        "\n",
        "        self.source = torch.tensor(self.source_list).to(device)\n",
        "        self.target = torch.tensor(self.target_list).to(device)\n",
        "\n",
        "    def _get_max_length(self, raw_data):\n",
        "        max_length = 0\n",
        "        for row in raw_data:\n",
        "            index, syllables, tags = row.rstrip('\\n').split('\\t')\n",
        "            syllables_list = syllables.split()\n",
        "            length = len(syllables_list)\n",
        "            if max_length < length:\n",
        "                max_length = length\n",
        "        return max_length\n",
        "\n",
        "    def __str__(self):\n",
        "        return 'source: {}, target: {}'.format(self.source.shape, self.target.shape)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.source)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return {\n",
        "            'source': self.source[idx],\n",
        "            'target': self.target[idx],\n",
        "        }\n",
        "\n",
        "\n",
        "print()\n",
        "\n",
        "train_dataset = NERDataset(raw_train_data, train_morph_token, train_pos_token, train_feature, device=device)\n",
        "test_dataset = NERDataset(raw_test_data, test_morph_token, test_pos_token, test_feature, device=device)\n",
        "\n",
        "print(train_dataset)\n",
        "print(test_dataset)\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 12/12 [00:00<00:00, 6250.05it/s]\n",
            "1832it [00:00, 18313.51it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "7319it [00:00, 15753.97it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "source: torch.Size([7319, 492, 184]), target: torch.Size([7319, 492])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y1JvWfFUvOlC"
      },
      "source": [
        "joblib.dump(train_dataset, 'train_dataset')\n",
        "joblib.dump(test_dataset, 'test_dataset')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G7TG9nM2ohhN"
      },
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "# test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "print('total steps: {}'.format(len(train_loader)), end='\\n\\n')\n",
        "\n",
        "sample = next(iter(train_loader))\n",
        "print('shape of {}: {}'.format('source', sample['source'].shape))\n",
        "print('shape of {}: {}'.format('target', sample['target'].shape), end='\\n\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-VCWSwjB8gQf",
        "outputId": "182e3d30-0ef1-4ede-903c-2a33ccf7b826"
      },
      "source": [
        "test_dataset = NERDataset(raw_test_data, test_morph_token, test_pos_token, test_feature, device=device)\n"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 12/12 [00:00<00:00, 16810.84it/s]\n",
            "995it [00:00, 22910.51it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ykym-Qpp_I4E",
        "outputId": "813f5f86-1867-46ec-cedd-a7aa012cef92"
      },
      "source": [
        "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
        "\n",
        "print('total steps: {}'.format(len(test_loader)), end='\\n\\n')\n",
        "sample = next(iter(train_loader))\n",
        "sample"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total steps: 995\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'source': tensor([[[-1.0909e-01,  1.4707e-01, -4.0618e-02,  ...,  0.0000e+00,\n",
              "            0.0000e+00,  0.0000e+00],\n",
              "          [-1.0909e-01,  1.4707e-01, -4.0618e-02,  ...,  0.0000e+00,\n",
              "            0.0000e+00,  0.0000e+00],\n",
              "          [-4.7728e-01,  6.9660e-01, -1.9908e-01,  ...,  0.0000e+00,\n",
              "            0.0000e+00,  0.0000e+00],\n",
              "          ...,\n",
              "          [ 3.0000e+00,  3.0000e+00,  3.0000e+00,  ...,  3.0000e+00,\n",
              "            3.0000e+00,  3.0000e+00],\n",
              "          [ 3.0000e+00,  3.0000e+00,  3.0000e+00,  ...,  3.0000e+00,\n",
              "            3.0000e+00,  3.0000e+00],\n",
              "          [ 3.0000e+00,  3.0000e+00,  3.0000e+00,  ...,  3.0000e+00,\n",
              "            3.0000e+00,  3.0000e+00]],\n",
              " \n",
              "         [[-5.3568e-02,  1.3946e-01,  1.9815e-02,  ...,  0.0000e+00,\n",
              "            0.0000e+00,  0.0000e+00],\n",
              "          [-5.3568e-02,  1.3946e-01,  1.9815e-02,  ...,  0.0000e+00,\n",
              "            0.0000e+00,  0.0000e+00],\n",
              "          [-4.7728e-01,  6.9660e-01, -1.9908e-01,  ...,  0.0000e+00,\n",
              "            0.0000e+00,  0.0000e+00],\n",
              "          ...,\n",
              "          [ 3.0000e+00,  3.0000e+00,  3.0000e+00,  ...,  3.0000e+00,\n",
              "            3.0000e+00,  3.0000e+00],\n",
              "          [ 3.0000e+00,  3.0000e+00,  3.0000e+00,  ...,  3.0000e+00,\n",
              "            3.0000e+00,  3.0000e+00],\n",
              "          [ 3.0000e+00,  3.0000e+00,  3.0000e+00,  ...,  3.0000e+00,\n",
              "            3.0000e+00,  3.0000e+00]],\n",
              " \n",
              "         [[-1.2304e-01,  1.4711e-01, -1.1725e-01,  ...,  0.0000e+00,\n",
              "            0.0000e+00,  0.0000e+00],\n",
              "          [-1.2304e-01,  1.4711e-01, -1.1725e-01,  ...,  0.0000e+00,\n",
              "            0.0000e+00,  0.0000e+00],\n",
              "          [-1.2304e-01,  1.4711e-01, -1.1725e-01,  ...,  0.0000e+00,\n",
              "            0.0000e+00,  0.0000e+00],\n",
              "          ...,\n",
              "          [ 3.0000e+00,  3.0000e+00,  3.0000e+00,  ...,  3.0000e+00,\n",
              "            3.0000e+00,  3.0000e+00],\n",
              "          [ 3.0000e+00,  3.0000e+00,  3.0000e+00,  ...,  3.0000e+00,\n",
              "            3.0000e+00,  3.0000e+00],\n",
              "          [ 3.0000e+00,  3.0000e+00,  3.0000e+00,  ...,  3.0000e+00,\n",
              "            3.0000e+00,  3.0000e+00]],\n",
              " \n",
              "         ...,\n",
              " \n",
              "         [[-4.0723e-04, -1.0497e-02,  3.7653e-02,  ...,  0.0000e+00,\n",
              "            0.0000e+00,  0.0000e+00],\n",
              "          [-4.0723e-04, -1.0497e-02,  3.7653e-02,  ...,  0.0000e+00,\n",
              "            0.0000e+00,  0.0000e+00],\n",
              "          [-4.7728e-01,  6.9660e-01, -1.9908e-01,  ...,  0.0000e+00,\n",
              "            0.0000e+00,  0.0000e+00],\n",
              "          ...,\n",
              "          [ 3.0000e+00,  3.0000e+00,  3.0000e+00,  ...,  3.0000e+00,\n",
              "            3.0000e+00,  3.0000e+00],\n",
              "          [ 3.0000e+00,  3.0000e+00,  3.0000e+00,  ...,  3.0000e+00,\n",
              "            3.0000e+00,  3.0000e+00],\n",
              "          [ 3.0000e+00,  3.0000e+00,  3.0000e+00,  ...,  3.0000e+00,\n",
              "            3.0000e+00,  3.0000e+00]],\n",
              " \n",
              "         [[-2.6665e-01, -3.0717e-01, -1.2813e-01,  ...,  0.0000e+00,\n",
              "            0.0000e+00,  0.0000e+00],\n",
              "          [ 3.7822e-02,  8.6317e-03, -2.0673e-02,  ...,  0.0000e+00,\n",
              "            1.0000e+00,  0.0000e+00],\n",
              "          [ 2.1188e-02,  6.7023e-02, -3.8909e-03,  ...,  1.0000e+00,\n",
              "            0.0000e+00,  0.0000e+00],\n",
              "          ...,\n",
              "          [ 3.0000e+00,  3.0000e+00,  3.0000e+00,  ...,  3.0000e+00,\n",
              "            3.0000e+00,  3.0000e+00],\n",
              "          [ 3.0000e+00,  3.0000e+00,  3.0000e+00,  ...,  3.0000e+00,\n",
              "            3.0000e+00,  3.0000e+00],\n",
              "          [ 3.0000e+00,  3.0000e+00,  3.0000e+00,  ...,  3.0000e+00,\n",
              "            3.0000e+00,  3.0000e+00]],\n",
              " \n",
              "         [[-4.3163e-01, -6.0719e-02, -4.5947e-01,  ...,  0.0000e+00,\n",
              "            0.0000e+00,  0.0000e+00],\n",
              "          [-2.0331e-02,  2.6539e-02,  4.5116e-02,  ...,  0.0000e+00,\n",
              "            1.0000e+00,  0.0000e+00],\n",
              "          [-2.0331e-02,  2.6539e-02,  4.5116e-02,  ...,  0.0000e+00,\n",
              "            1.0000e+00,  0.0000e+00],\n",
              "          ...,\n",
              "          [ 3.0000e+00,  3.0000e+00,  3.0000e+00,  ...,  3.0000e+00,\n",
              "            3.0000e+00,  3.0000e+00],\n",
              "          [ 3.0000e+00,  3.0000e+00,  3.0000e+00,  ...,  3.0000e+00,\n",
              "            3.0000e+00,  3.0000e+00],\n",
              "          [ 3.0000e+00,  3.0000e+00,  3.0000e+00,  ...,  3.0000e+00,\n",
              "            3.0000e+00,  3.0000e+00]]], device='cuda:0', dtype=torch.float64),\n",
              " 'target': tensor([[13, 13,  2,  ...,  3,  3,  3],\n",
              "         [13, 13,  2,  ...,  3,  3,  3],\n",
              "         [13, 13, 13,  ...,  3,  3,  3],\n",
              "         ...,\n",
              "         [ 6, 11,  2,  ...,  3,  3,  3],\n",
              "         [13, 13, 13,  ...,  3,  3,  3],\n",
              "         [13, 13, 13,  ...,  3,  3,  3]], device='cuda:0')}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "5-AeDvqnohhN"
      },
      "source": [
        "## 모델링"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d1exnmk-v67l",
        "outputId": "30cd673b-586a-4444-ccc7-43619e425638"
      },
      "source": [
        "!pip install pytorch-crf"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pytorch-crf\n",
            "  Downloading https://files.pythonhosted.org/packages/96/7d/4c4688e26ea015fc118a0327e5726e6596836abce9182d3738be8ec2e32a/pytorch_crf-0.7.2-py3-none-any.whl\n",
            "Installing collected packages: pytorch-crf\n",
            "Successfully installed pytorch-crf-0.7.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "6y0ArDr0ohhN"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchcrf import CRF\n",
        "\n",
        "\n",
        "class RNN_CRF(nn.Module):\n",
        "    def __init__(self, pretrained_weight, embedding_size, hidden_size, output_size, dropout=0.5):\n",
        "        super(RNN_CRF, self).__init__()\n",
        "\n",
        "        # self.embedding = nn.Embedding.from_pretrained(pretrained_weight)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "        self.rnn = nn.GRU(\n",
        "            embedding_size,\n",
        "            hidden_size,\n",
        "            batch_first=True,\n",
        "            bidirectional=True\n",
        "        )\n",
        "\n",
        "        # CRF layer\n",
        "        self.crf = CRF(output_size, batch_first=True)\n",
        "\n",
        "        # (batch_size, seq_len, hidden_size * 2) -> (batch_size, seq_len, output_size)\n",
        "        self.fc = nn.Linear(hidden_size * 2, output_size)\n",
        "\n",
        "    def forward(self, inputs, labels=None):\n",
        "        # (batch_size, seq_len) -> (batch_size, seq_len, embedding_size)\n",
        "        inputs = inputs.float()\n",
        "        outputs, hidden = self.rnn(inputs)\n",
        "\n",
        "        # (batch_size, seq_len, hidden_size * 2)\n",
        "        outputs = self.dropout(outputs)\n",
        "\n",
        "        # (batch_size, seq_len, hidden_size * 2) -> (batch_size, seq_len, output_size)\n",
        "        logits = self.fc(outputs)\n",
        "\n",
        "        if labels is not None:\n",
        "            log_likelihood = self.crf(\n",
        "                emissions=logits,\n",
        "                tags=labels,\n",
        "                reduction=\"mean\"\n",
        "            )\n",
        "            loss = log_likelihood * -1.0\n",
        "            return loss\n",
        "        else:\n",
        "            output = self.crf.decode(emissions=logits)\n",
        "            return output"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "cgRdZusMohhN"
      },
      "source": [
        "## Train and Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hfU3OtlIohhN"
      },
      "source": [
        "import torch\n",
        "import torch.optim as optim\n",
        "from seqeval.metrics import classification_report\n",
        "\n",
        "\n",
        "def train(model, train_data, test_data=None, num_epochs=20):\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "    accuracy_list = []\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        losses = []\n",
        "\n",
        "        for step, batch in enumerate(train_data):\n",
        "            source = batch['source']\n",
        "            target = batch['target']\n",
        "            \n",
        "            loss = model.forward(source, target)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            if (step + 1) % 50 == 0:\n",
        "                print('{} step processed.. current loss : {}'.format(step + 1, loss.data.item()))\n",
        "            losses.append(loss.data.item())\n",
        "\n",
        "        print('Average Loss : {}'.format(np.mean(losses)))\n",
        "\n",
        "        torch.save(model, 'savepoint.model')\n",
        "        do_test(model, test_data)\n",
        "\n",
        "\n",
        "def tensor2list(input_tensor):\n",
        "    return input_tensor.cpu().detach().numpy().tolist()\n",
        "\n",
        "\n",
        "def do_test(model, test_dataloader):\n",
        "    model.eval()\n",
        "    \n",
        "    _, idx2tag = load_tag_dict()\n",
        "\n",
        "    predicts, answers = [], []\n",
        "    \n",
        "    for step, batch in enumerate(test_dataloader):\n",
        "        source = batch['source']\n",
        "        target = batch['target']\n",
        "\n",
        "        # 예측 라벨 출력\n",
        "        output = model(source)\n",
        "\n",
        "        # 성능 평가를 위해 예측 값과 정답 값 리스트에 저장\n",
        "        for idx, answer in enumerate(tensor2list(target)):\n",
        "            answers.append([idx2tag[e].replace(\"_\", \"-\") for e in answer if idx2tag[e] != \"<SP>\" and idx2tag[e] != \"<PAD>\"])\n",
        "            predicts.append([idx2tag[e].replace(\"_\", \"-\") for i, e in enumerate(output[idx]) if idx2tag[answer[i]] != \"<SP>\" and idx2tag[answer[i]] != \"<PAD>\"] )\n",
        "\n",
        "    print(len(predicts))\n",
        "    \n",
        "    # 성능 평가\n",
        "    print(classification_report(answers, predicts))"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kZjeI_jXohhN",
        "outputId": "89641566-5b26-4c52-8fb3-fc4b6406c4d4"
      },
      "source": [
        "# load glove embeddings\n",
        "import os\n",
        "import joblib\n",
        "import torch\n",
        "\n",
        "train_weights = joblib.load(os.path.join(BASE_DIR, 'train_emb_word_dict_mecab_sp.pickle'))\n",
        "dev_weights = joblib.load(os.path.join(BASE_DIR, 'dev_emb_word_dict_mecab_sp.pickle'))\n",
        "\n",
        "weights = torch.FloatTensor(list({**train_weights, **dev_weights}.values())).cuda()\n",
        "\n",
        "print(weights.shape)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([23583, 128])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q-lW9bc1ohhN"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 477
        },
        "id": "IJ_-WXHVohhN",
        "outputId": "f364dbe3-5db3-445b-eeb9-6987442135c4"
      },
      "source": [
        "input_size = 184\n",
        "hidden_size = 128\n",
        "output_size = 14\n",
        "dropout = 0.3\n",
        "\n",
        "model = RNN_CRF(weights, input_size, hidden_size, output_size, dropout=dropout).to(device)\n",
        "print(model)\n",
        "\n",
        "train(model, train_loader, test_loader)"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RNN_CRF(\n",
            "  (dropout): Dropout(p=0.3, inplace=False)\n",
            "  (rnn): GRU(184, 128, batch_first=True, bidirectional=True)\n",
            "  (crf): CRF(num_tags=14)\n",
            "  (fc): Linear(in_features=256, out_features=14, bias=True)\n",
            ")\n",
            "50 step processed.. current loss : 26.65117645263672\n",
            "100 step processed.. current loss : 15.336833953857422\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 12/12 [00:00<00:00, 4899.41it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Average Loss : 41.99581110581108\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-77-125e9231cade>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-76-140a837e3457>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_data, test_data, num_epochs)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'savepoint.model'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mdo_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-76-140a837e3457>\u001b[0m in \u001b[0;36mdo_test\u001b[0;34m(model, test_dataloader)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0;31m# 예측 라벨 출력\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;31m# 성능 평가를 위해 예측 값과 정답 값 리스트에 저장\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-58-c4d797582528>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs, labels)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcrf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memissions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'tolist'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S5DR4udP_fL1",
        "outputId": "7962fd96-db14-43e5-a2dc-12df9c586cdb"
      },
      "source": [
        "!pip install seqeval"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting seqeval\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9d/2d/233c79d5b4e5ab1dbf111242299153f3caddddbb691219f363ad55ce783d/seqeval-1.2.2.tar.gz (43kB)\n",
            "\r\u001b[K     |███████▌                        | 10kB 22.2MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 20kB 29.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 30kB 34.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 40kB 36.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 51kB 8.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from seqeval) (1.18.5)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.6/dist-packages (from seqeval) (0.22.2.post1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.21.3->seqeval) (0.17.0)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.4.1)\n",
            "Building wheels for collected packages: seqeval\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-cp36-none-any.whl size=16171 sha256=0d2a82c0ea7846ca1acd00f5ac82b2b4af8ff7f5e3addcc383a9eb9288bec644\n",
            "  Stored in directory: /root/.cache/pip/wheels/52/df/1b/45d75646c37428f7e626214704a0e35bd3cfc32eda37e59e5f\n",
            "Successfully built seqeval\n",
            "Installing collected packages: seqeval\n",
            "Successfully installed seqeval-1.2.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ld-xT7sU9RoA"
      },
      "source": [
        ""
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8loUPVgiohhN"
      },
      "source": [
        "## Test Macro F1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1bZGoMneohhN",
        "outputId": "071aa9ea-b935-43ce-c744-fc355f61d7d9"
      },
      "source": [
        "do_test(model, test_loader)"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 12/12 [00:00<00:00, 29127.11it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "995\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "          DT       0.75      1.00      0.85    154027\n",
            "          LC       0.00      0.00      0.00       537\n",
            "          OG       0.00      0.00      0.00       973\n",
            "          PS       0.00      0.00      0.00       742\n",
            "          TI       0.00      0.00      0.00        95\n",
            "\n",
            "   micro avg       0.75      0.98      0.85    156374\n",
            "   macro avg       0.15      0.20      0.17    156374\n",
            "weighted avg       0.74      0.98      0.84    156374\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "E4BRfxXZohhN"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}