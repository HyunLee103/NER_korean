{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "source": [
    "## Raw Data 로드"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "BASE_DIR = 'data'\n",
    "\n",
    "def load_data(file_name):\n",
    "    with open(os.path.join(BASE_DIR, file_name), 'r', encoding='utf-8') as fp:\n",
    "        return fp.readlines()\n",
    "\n",
    "raw_train_data = load_data('ner_train.txt')\n",
    "raw_test_data = load_data('ner_dev.txt')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "source": [
    "tmp_data = raw_train_data[0]\n",
    "tmp_data"
   ],
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 2,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'366\\t새 벽 출 조 시 <SP> 야 영 적 극 <SP> 권 장 하 ㅂ 니 다 <SP> .\\tB_TI I_TI O O O <SP> O O O O <SP> O O O O O O <SP> O\\n'"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ]
  },
  {
   "source": [
    "## Feature 로드\n",
    "\n",
    "```\n",
    "{형태소: 161차원 vector}\n",
    "```"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(184,)"
      ]
     },
     "metadata": {},
     "execution_count": 136
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "train_feature = joblib.load(os.path.join(BASE_DIR, 'train_concat_features'))\n",
    "test_feature = joblib.load(os.path.join(BASE_DIR, 'dev_concat_features'))\n",
    "\n",
    "train_feature['새벽'].shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "source": [
    "## 통합 데이터셋 만들기\n",
    "\n",
    "```\n",
    "{형태소: 161차원 vector}\n",
    "```\n",
    "\n",
    "Input: 음절단위 문장\n",
    "\n",
    "1. 합친다\n",
    "2. 형태소로짼다\n",
    "3. 아까했던 헝태소: 벡터 를 (길이) 만큼 한다\n",
    "4. 그러면 (seq_len, 161) 의 벡터가 데이터 크기만큼 나온다.\n",
    "5. <SOS\\> 벡터, <EOS\\> 벡터, <PAD\\> 벡터를 준다.\n",
    "6. ?"
   ],
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Mecab\n",
    "\n",
    "\n",
    "def convert_sentence(sentence):\n",
    "    return sentence.replace(' ', '').replace('<SP>', ' ')\n",
    "\n",
    "\n",
    "def tag_pos(sentence):\n",
    "    syllable = sentence.split(' ')\n",
    "    converted = convert_sentence(sentence)\n",
    "    morpher = Mecab()\n",
    "    morph_pos_list = morpher.pos(converted)\n",
    "    morphs_list = []\n",
    "\n",
    "    pos_list = []\n",
    "    index = 0\n",
    "\n",
    "    for morph_pos in morph_pos_list:\n",
    "        morph, pos = morph_pos\n",
    "        morphs_list.append(morph)\n",
    "        pos_list.append('B_{}'.format(pos))\n",
    "\n",
    "        for i in range(1, len(morph)):\n",
    "            pos_list.append('I_{}'.format(pos))\n",
    "\n",
    "        index += len(morph)\n",
    "        if index < len(syllable):\n",
    "            if syllable[index] == '<SP>':\n",
    "                morphs_list.append('<SP>')\n",
    "                pos_list.append('<SP>')\n",
    "                index += 1\n",
    "\n",
    "    return morphs_list, ' '.join(pos_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 7319/7319 [00:00<00:00, 208751.16it/s]\n",
      "100%|██████████| 995/995 [00:00<00:00, 225110.98it/s]\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['data/test_morph_token']"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "import joblib\n",
    "from konlpy.tag import Mecab\n",
    "from tqdm import tqdm\n",
    "\n",
    "# <SP> 포함시키기\n",
    "def getToken_with_sp(file):\n",
    "    mecab = Mecab()\n",
    "\n",
    "    with open(file, 'r', encoding='utf-8') as fs:\n",
    "        total_data = fs.readlines()\n",
    "\n",
    "    sentences = []\n",
    "    tags = []\n",
    "    for data in tqdm(total_data):\n",
    "        id, sentence, tag = data.rstrip('\\n').split('\\t')\n",
    "        sentences.append(sentence.replace(' ', '').replace('<SP>', ' <SP> '))\n",
    "        tags.append(tag)\n",
    "\n",
    "    morph_token = []\n",
    "    for sentence in sentences:\n",
    "        token_with_sp = sentence.split()\n",
    "\n",
    "        for ind, word in enumerate(token_with_sp):\n",
    "            if word != '<SP>':\n",
    "                morph = mecab.morphs(word)\n",
    "                token_with_sp[ind] = morph\n",
    "            else:\n",
    "                token_with_sp[ind] = ['<SP>']\n",
    "\n",
    "        token_with_sp = [y for x in token_with_sp for y in x]\n",
    "        morph_token.append(token_with_sp)\n",
    "\n",
    "    return morph_token\n",
    "\n",
    "\n",
    "train_token = getToken_with_sp('data/ner_train.txt')\n",
    "dev_token = getToken_with_sp('data/ner_dev.txt')\n",
    "\n",
    "joblib.dump(train_token, 'data/train_morph_token')\n",
    "joblib.dump(dev_token, 'data/test_morph_token')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 7319/7319 [00:00<00:00, 147605.52it/s]\n",
      "100%|██████████| 995/995 [00:00<00:00, 150033.52it/s]\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['data/test_pos_token']"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "# POS_token 만들기\n",
    "def getPos_with_sp(file):\n",
    "    mecab = Mecab()\n",
    "    with open(file, 'r', encoding='utf-8') as fs:\n",
    "        total_data = fs.readlines()\n",
    "\n",
    "    sentences = []\n",
    "    for data in tqdm(total_data):\n",
    "        id, sentence, tag = data.rstrip('\\n').split('\\t')\n",
    "        sentences.append(sentence.replace(' ', '').replace('<SP>', ' <SP> '))\n",
    "\n",
    "    pos_token = []\n",
    "    for sentence in sentences:\n",
    "        pos_with_sp = sentence.split()\n",
    "\n",
    "        for ind, word in enumerate(pos_with_sp):\n",
    "            if word != '<SP>':\n",
    "                morph_pos = mecab.pos(word)\n",
    "                pos = [pos for morph, pos in morph_pos]\n",
    "                pos_with_sp[ind] = pos\n",
    "            else:\n",
    "                pos_with_sp[ind] = ['<SP>']\n",
    "\n",
    "        pos_with_sp = [y for x in pos_with_sp for y in x]\n",
    "        pos_token.append(pos_with_sp)\n",
    "\n",
    "    return pos_token\n",
    "\n",
    "train_pos_token = getPos_with_sp('data/ner_train.txt')\n",
    "dev_pos_token = getPos_with_sp('data/ner_dev.txt')\n",
    "\n",
    "joblib.dump(train_pos_token, 'data/train_pos_token')\n",
    "joblib.dump(dev_pos_token, 'data/test_pos_token')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "token = joblib.load('data/train_pos_token')"
   ]
  },
  {
   "source": [
    "## `Dataset` 객체로 만들기"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def load_tag_dict():\n",
    "    fp = open(os.path.join('data', 'tag_vocab.txt'), 'r')\n",
    "    tag_dict = {'<UNK>': 0, '<SP>': 1, '<EOS>': 2, '<PAD>': 3}\n",
    "\n",
    "    index = 2\n",
    "    for line in tqdm(fp.readlines()):\n",
    "        tag = line.strip()\n",
    "        tag_dict[tag] = index\n",
    "        index += 1\n",
    "\n",
    "    return tag_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 12/12 [00:00<00:00, 136400.13it/s]\n",
      "  0%|          | 3/7319 [00:00<04:33, 26.74it/s]\n",
      "100%|██████████| 7319/7319 [00:17<00:00, 412.33it/s]\n",
      "100%|██████████| 12/12 [00:00<00:00, 22104.37it/s]\n",
      "100%|██████████| 995/995 [00:04<00:00, 232.79it/s]\n",
      "{'source': tensor([[[-0.0571,  0.0895, -0.0352,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [-0.0571,  0.0895, -0.0352,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0209, -0.0194, -0.0035,  ...,  1.0000,  0.0000,  0.0000],\n",
      "         ...,\n",
      "         [ 3.0000,  3.0000,  3.0000,  ...,  3.0000,  3.0000,  3.0000],\n",
      "         [ 3.0000,  3.0000,  3.0000,  ...,  3.0000,  3.0000,  3.0000],\n",
      "         [ 3.0000,  3.0000,  3.0000,  ...,  3.0000,  3.0000,  3.0000]],\n",
      "\n",
      "        [[-0.1091,  0.1471, -0.0406,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [-0.1091,  0.1471, -0.0406,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [-0.4773,  0.6966, -0.1991,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         ...,\n",
      "         [ 3.0000,  3.0000,  3.0000,  ...,  3.0000,  3.0000,  3.0000],\n",
      "         [ 3.0000,  3.0000,  3.0000,  ...,  3.0000,  3.0000,  3.0000],\n",
      "         [ 3.0000,  3.0000,  3.0000,  ...,  3.0000,  3.0000,  3.0000]],\n",
      "\n",
      "        [[-0.4646,  0.0060,  0.1109,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [-0.0409,  0.1220,  0.0130,  ...,  1.0000,  0.0000,  0.0000],\n",
      "         [-0.0409,  0.1220,  0.0130,  ...,  1.0000,  0.0000,  0.0000],\n",
      "         ...,\n",
      "         [ 3.0000,  3.0000,  3.0000,  ...,  3.0000,  3.0000,  3.0000],\n",
      "         [ 3.0000,  3.0000,  3.0000,  ...,  3.0000,  3.0000,  3.0000],\n",
      "         [ 3.0000,  3.0000,  3.0000,  ...,  3.0000,  3.0000,  3.0000]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0277,  0.0234, -0.0112,  ...,  0.0000,  1.0000,  0.0000],\n",
      "         [ 0.0277,  0.0234, -0.0112,  ...,  0.0000,  1.0000,  0.0000],\n",
      "         [ 0.0277,  0.0234, -0.0112,  ...,  0.0000,  1.0000,  0.0000],\n",
      "         ...,\n",
      "         [ 3.0000,  3.0000,  3.0000,  ...,  3.0000,  3.0000,  3.0000],\n",
      "         [ 3.0000,  3.0000,  3.0000,  ...,  3.0000,  3.0000,  3.0000],\n",
      "         [ 3.0000,  3.0000,  3.0000,  ...,  3.0000,  3.0000,  3.0000]],\n",
      "\n",
      "        [[-0.1499, -0.0372, -0.2280,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [-0.0439,  0.1400,  0.1093,  ...,  0.0000,  1.0000,  0.0000],\n",
      "         [-0.4773,  0.6966, -0.1991,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         ...,\n",
      "         [ 3.0000,  3.0000,  3.0000,  ...,  3.0000,  3.0000,  3.0000],\n",
      "         [ 3.0000,  3.0000,  3.0000,  ...,  3.0000,  3.0000,  3.0000],\n",
      "         [ 3.0000,  3.0000,  3.0000,  ...,  3.0000,  3.0000,  3.0000]],\n",
      "\n",
      "        [[-0.4316, -0.0607, -0.4595,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [-0.1026,  0.0498, -0.1037,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [-0.3998,  0.0629, -0.0718,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         ...,\n",
      "         [ 3.0000,  3.0000,  3.0000,  ...,  3.0000,  3.0000,  3.0000],\n",
      "         [ 3.0000,  3.0000,  3.0000,  ...,  3.0000,  3.0000,  3.0000],\n",
      "         [ 3.0000,  3.0000,  3.0000,  ...,  3.0000,  3.0000,  3.0000]]],\n",
      "       dtype=torch.float64), 'target': tensor([[ 7, 12, 13,  ...,  3,  3,  3],\n",
      "        [13, 13,  2,  ...,  3,  3,  3],\n",
      "        [13,  6, 11,  ...,  3,  3,  3],\n",
      "        ...,\n",
      "        [13, 13, 13,  ...,  3,  3,  3],\n",
      "        [13, 13,  2,  ...,  3,  3,  3],\n",
      "        [13, 13, 13,  ...,  3,  3,  3]])}\n",
      "source: torch.Size([995, 221, 184]), target: torch.Size([995, 221])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "UNK_TOKEN = 0\n",
    "SP_TOKEN = 1\n",
    "EOS_TOKEN = 2\n",
    "PAD_TOKEN = 3\n",
    "\n",
    "FEATURE_SIZE = 184\n",
    "\n",
    "UNK_VECTOR = [UNK_TOKEN] * FEATURE_SIZE\n",
    "SP_VECTOR = [SP_TOKEN] * FEATURE_SIZE\n",
    "EOS_VECTOR = [EOS_TOKEN] * FEATURE_SIZE\n",
    "PAD_VECTOR = [PAD_TOKEN] * FEATURE_SIZE\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "\n",
    "class NERDataset(Dataset):\n",
    "    def __init__(self, raw_data, feature=None, device='cpu'):\n",
    "        super(NERDataset, self).__init__()\n",
    "        self.source_list = []\n",
    "        self.target_list = []\n",
    "\n",
    "        tag_dict = load_tag_dict()\n",
    "        max_length = self._get_max_length(raw_data)\n",
    "\n",
    "        for row in tqdm(raw_data):\n",
    "            index, syllables, tags = row.rstrip('\\n').split('\\t')\n",
    "            syllables_list = syllables.split()\n",
    "            morphs_list, pos_list = tag_pos(syllables)\n",
    "            tags_list = tags.split()\n",
    "\n",
    "            encoded_syllable_list = []\n",
    "            if feature:\n",
    "                for morph in morphs_list:\n",
    "                    if morph in feature.keys():\n",
    "                        morph_size = len(morph) if morph != '<SP>' else 1\n",
    "                        encoded_syllable_list += [feature[morph]] * morph_size\n",
    "                    else:\n",
    "                        encoded_syllable_list += [UNK_VECTOR] * len(morph)\n",
    "\n",
    "                padding_size = max_length - len(encoded_syllable_list)\n",
    "                encoded_syllable_list.append(EOS_VECTOR)\n",
    "                encoded_syllable_list += [PAD_VECTOR] * padding_size\n",
    "\n",
    "                self.source_list.append(encoded_syllable_list)\n",
    "            else:\n",
    "                # TODO: raw feature generation\n",
    "                pass\n",
    "\n",
    "            encoded_tag_list = []\n",
    "            for tag in tags_list:\n",
    "                if tag in tag_dict.keys():\n",
    "                    encoded_tag_list.append(tag_dict[tag])\n",
    "                else:\n",
    "                    encoded_tag_list.append(tag_dict['<UNK>'])\n",
    "\n",
    "            padding_size = max_length - len(encoded_tag_list)\n",
    "            encoded_tag_list.append(tag_dict['<EOS>'])\n",
    "            encoded_tag_list += [tag_dict['<PAD>']] * padding_size\n",
    "\n",
    "            self.target_list.append(encoded_tag_list)\n",
    "\n",
    "        self.source = torch.tensor(self.source_list).to(device)\n",
    "        self.target = torch.tensor(self.target_list).to(device)\n",
    "\n",
    "    def _get_max_length(self, raw_data):\n",
    "        max_length = 0\n",
    "        for row in raw_data:\n",
    "            index, syllables, tags = row.rstrip('\\n').split('\\t')\n",
    "            syllables_list = syllables.split()\n",
    "            length = len(syllables_list)\n",
    "            if max_length < length:\n",
    "                max_length = length\n",
    "        return max_length\n",
    "\n",
    "    def __str__(self):\n",
    "        return 'source: {}, target: {}'.format(self.source.shape, self.target.shape)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.source)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'source': self.source[idx],\n",
    "            'target': self.target[idx],\n",
    "        }\n",
    "\n",
    "\n",
    "print()\n",
    "\n",
    "train_dataset = NERDataset(raw_train_data, train_feature, device=device)\n",
    "test_dataset = NERDataset(raw_test_data, test_feature, device=device)\n",
    "\n",
    "print(train_dataset)\n",
    "print(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "total steps: 115\n\nshape of source: torch.Size([64, 221, 184])\nshape of target: torch.Size([64, 221])\n\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'source': tensor([[[-1.4930e-01, -2.0743e-04, -2.7540e-01,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  1.0000e+00],\n",
       "          [-1.6598e-01, -1.2423e-02, -4.6280e-01,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [-4.7728e-01,  6.9660e-01, -1.9908e-01,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  1.0000e+00],\n",
       "          ...,\n",
       "          [ 3.0000e+00,  3.0000e+00,  3.0000e+00,  ...,  3.0000e+00,\n",
       "            3.0000e+00,  3.0000e+00],\n",
       "          [ 3.0000e+00,  3.0000e+00,  3.0000e+00,  ...,  3.0000e+00,\n",
       "            3.0000e+00,  3.0000e+00],\n",
       "          [ 3.0000e+00,  3.0000e+00,  3.0000e+00,  ...,  3.0000e+00,\n",
       "            3.0000e+00,  3.0000e+00]],\n",
       " \n",
       "         [[-1.4132e-01,  4.0622e-02,  1.1855e-02,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [-2.2431e-01, -1.6861e-01, -6.3922e-02,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  1.0000e+00],\n",
       "          [-4.8806e-01, -6.9621e-02,  7.1299e-01,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  1.0000e+00],\n",
       "          ...,\n",
       "          [ 3.0000e+00,  3.0000e+00,  3.0000e+00,  ...,  3.0000e+00,\n",
       "            3.0000e+00,  3.0000e+00],\n",
       "          [ 3.0000e+00,  3.0000e+00,  3.0000e+00,  ...,  3.0000e+00,\n",
       "            3.0000e+00,  3.0000e+00],\n",
       "          [ 3.0000e+00,  3.0000e+00,  3.0000e+00,  ...,  3.0000e+00,\n",
       "            3.0000e+00,  3.0000e+00]],\n",
       " \n",
       "         [[-1.3308e-01, -3.4578e-02,  1.9711e-01,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  1.0000e+00],\n",
       "          [-1.0359e-01, -1.2420e-01, -9.0963e-02,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  1.0000e+00],\n",
       "          [-3.9981e-01,  6.2871e-02, -7.1845e-02,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  1.0000e+00],\n",
       "          ...,\n",
       "          [ 3.0000e+00,  3.0000e+00,  3.0000e+00,  ...,  3.0000e+00,\n",
       "            3.0000e+00,  3.0000e+00],\n",
       "          [ 3.0000e+00,  3.0000e+00,  3.0000e+00,  ...,  3.0000e+00,\n",
       "            3.0000e+00,  3.0000e+00],\n",
       "          [ 3.0000e+00,  3.0000e+00,  3.0000e+00,  ...,  3.0000e+00,\n",
       "            3.0000e+00,  3.0000e+00]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[-1.2050e-01,  4.0708e-02, -1.7899e-01,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  1.0000e+00],\n",
       "          [-1.2050e-01,  4.0708e-02, -1.7899e-01,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  1.0000e+00],\n",
       "          [-1.6598e-01, -1.2423e-02, -4.6280e-01,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          ...,\n",
       "          [ 3.0000e+00,  3.0000e+00,  3.0000e+00,  ...,  3.0000e+00,\n",
       "            3.0000e+00,  3.0000e+00],\n",
       "          [ 3.0000e+00,  3.0000e+00,  3.0000e+00,  ...,  3.0000e+00,\n",
       "            3.0000e+00,  3.0000e+00],\n",
       "          [ 3.0000e+00,  3.0000e+00,  3.0000e+00,  ...,  3.0000e+00,\n",
       "            3.0000e+00,  3.0000e+00]],\n",
       " \n",
       "         [[ 3.1888e-02, -6.2555e-02,  7.7152e-03,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 3.1888e-02, -6.2555e-02,  7.7152e-03,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 3.1888e-02, -6.2555e-02,  7.7152e-03,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          ...,\n",
       "          [ 3.0000e+00,  3.0000e+00,  3.0000e+00,  ...,  3.0000e+00,\n",
       "            3.0000e+00,  3.0000e+00],\n",
       "          [ 3.0000e+00,  3.0000e+00,  3.0000e+00,  ...,  3.0000e+00,\n",
       "            3.0000e+00,  3.0000e+00],\n",
       "          [ 3.0000e+00,  3.0000e+00,  3.0000e+00,  ...,  3.0000e+00,\n",
       "            3.0000e+00,  3.0000e+00]],\n",
       " \n",
       "         [[-3.2996e-01, -1.9932e-01, -1.8753e-01,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [-1.4447e-01, -6.5430e-02, -7.2441e-02,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  1.0000e+00],\n",
       "          [-4.7728e-01,  6.9660e-01, -1.9908e-01,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  1.0000e+00],\n",
       "          ...,\n",
       "          [ 3.0000e+00,  3.0000e+00,  3.0000e+00,  ...,  3.0000e+00,\n",
       "            3.0000e+00,  3.0000e+00],\n",
       "          [ 3.0000e+00,  3.0000e+00,  3.0000e+00,  ...,  3.0000e+00,\n",
       "            3.0000e+00,  3.0000e+00],\n",
       "          [ 3.0000e+00,  3.0000e+00,  3.0000e+00,  ...,  3.0000e+00,\n",
       "            3.0000e+00,  3.0000e+00]]], dtype=torch.float64),\n",
       " 'target': tensor([[ 3,  8,  2,  ...,  3,  3,  3],\n",
       "         [ 6, 13, 13,  ...,  3,  3,  3],\n",
       "         [13, 13, 13,  ...,  3,  3,  3],\n",
       "         ...,\n",
       "         [ 3,  8,  8,  ...,  3,  3,  3],\n",
       "         [ 4,  9,  9,  ...,  3,  3,  3],\n",
       "         [13, 13,  2,  ...,  3,  3,  3]])}"
      ]
     },
     "metadata": {},
     "execution_count": 139
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "print('total steps: {}'.format(len(train_loader)), end='\\n\\n')\n",
    "\n",
    "sample = next(iter(test_loader))\n",
    "print('shape of {}: {}'.format('source', sample['source'].shape))\n",
    "print('shape of {}: {}'.format('target', sample['target'].shape), end='\\n\\n')\n",
    "\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['train_loader']"
      ]
     },
     "metadata": {},
     "execution_count": 40
    }
   ],
   "source": [
    "joblib.dump(train_loader, 'train_loader')"
   ]
  },
  {
   "source": [
    "## 모델링"
   ],
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchcrf import CRF\n",
    "\n",
    "\n",
    "class RNN_CRF(nn.Module):\n",
    "    def __init__(self, pretrained_weight, embedding_size, hidden_size, output_size, dropout=0.5):\n",
    "        super(RNN_CRF, self).__init__()\n",
    "\n",
    "        # self.embedding = nn.Embedding.from_pretrained(pretrained_weight)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        self.rnn = nn.GRU(\n",
    "            embedding_size,\n",
    "            hidden_size,\n",
    "            batch_first=True,\n",
    "            bidirectional=True\n",
    "        )\n",
    "\n",
    "        # CRF layer\n",
    "        self.crf = CRF(output_size, batch_first=True)\n",
    "\n",
    "        # (batch_size, seq_len, hidden_size * 2) -> (batch_size, seq_len, output_size)\n",
    "        self.fc = nn.Linear(hidden_size * 2, output_size)\n",
    "\n",
    "    def forward(self, inputs, labels=None):\n",
    "        # (batch_size, seq_len) -> (batch_size, seq_len, embedding_size)\n",
    "        inputs = inputs.float()\n",
    "        outputs, hidden = self.rnn(inputs)\n",
    "\n",
    "        # (batch_size, seq_len, hidden_size * 2)\n",
    "        outputs = self.dropout(outputs)\n",
    "\n",
    "        # (batch_size, seq_len, hidden_size * 2) -> (batch_size, seq_len, output_size)\n",
    "        logits = self.fc(outputs)\n",
    "\n",
    "        if labels is not None:\n",
    "            log_likelihood = self.crf(\n",
    "                emissions=logits,\n",
    "                tags=labels,\n",
    "                reduction=\"mean\"\n",
    "            )\n",
    "            loss = log_likelihood * -1.0\n",
    "            return loss\n",
    "        else:\n",
    "            output = self.crf.decode(emissions=logits)\n",
    "            return output"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "source": [
    "## Train and Evaluate"
   ],
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "def train(model, train_data, test_data=None, num_epochs=20):\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.005)\n",
    "    accuracy_list = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        losses = []\n",
    "\n",
    "        for step, batch in enumerate(train_data):\n",
    "            source = batch['source']\n",
    "            target = batch['target']\n",
    "            \n",
    "            loss = model.forward(source, target)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if (step + 1) % 50 == 0:\n",
    "                print(\n",
    "                    '{} step processed.. current loss : {}'.format(\n",
    "                        step + 1,\n",
    "                        loss.data.item()\n",
    "                    )\n",
    "                )\n",
    "            losses.append(loss.data.item())\n",
    "\n",
    "        print('Average Loss : {}'.format(np.mean(losses)))\n",
    "\n",
    "        torch.save(model, 'output/savepoint.model')\n",
    "        # do_test(model, test_data, idx2tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.float64\ntorch.Size([23583, 128])\n"
     ]
    }
   ],
   "source": [
    "# load glove embeddings\n",
    "import joblib\n",
    "import torch\n",
    "\n",
    "train_weights = joblib.load('data/train_emb_word_dict_mecab_sp.pickle')\n",
    "dev_weights = joblib.load('data/dev_emb_word_dict_mecab_sp.pickle')\n",
    "\n",
    "weights = torch.DoubleTensor(list({**train_weights, **dev_weights}.values()))\n",
    "print(weights.dtype)\n",
    "print(weights.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "RNN_CRF(\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "  (rnn): GRU(183, 256, batch_first=True, bidirectional=True)\n",
      "  (crf): CRF(num_tags=14)\n",
      "  (fc): Linear(in_features=512, out_features=14, bias=True)\n",
      ")\n",
      "torch.float32\n",
      "torch.int64\n",
      "torch.float32\n",
      "torch.int64\n",
      "torch.float32\n",
      "torch.int64\n",
      "torch.float32\n",
      "torch.int64\n",
      "torch.float32\n",
      "torch.int64\n",
      "torch.float32\n",
      "torch.int64\n",
      "torch.float32\n",
      "torch.int64\n",
      "torch.float32\n",
      "torch.int64\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-125-35a5735f4048>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-123-b84c3313eabc>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_data, test_data, num_epochs)\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'target'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-122-37d2d191694d>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs, labels)\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;31m# (batch_size, seq_len) -> (batch_size, seq_len, embedding_size)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;31m# (batch_size, seq_len, hidden_size * 2)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/School/4-2/ai/homeworks/hackathon2/venv/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/School/4-2/ai/homeworks/hackathon2/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    737\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_forward_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    738\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 739\u001b[0;31m             result = _VF.gru(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[0m\u001b[1;32m    740\u001b[0m                              self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[1;32m    741\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "embedding_size = 183\n",
    "hidden_size = 256\n",
    "output_size = 14\n",
    "\n",
    "# glove matrix 풀어넣는 일만 남았어요\n",
    "model = RNN_CRF(weights, embedding_size, hidden_size, output_size)\n",
    "print(model)\n",
    "\n",
    "train(model, train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "## Test Macro F1"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ]
}