{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5-final"
    },
    "orig_nbformat": 2,
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "console.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HyunLee103/NER_korean/blob/main/console.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BAazdWu9ongG",
        "outputId": "978bf380-fa86-45a6-ad93-e93616ec5206"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "spklXwDCohhL"
      },
      "source": [
        "## Raw Data 로드"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "jLuGUEobohhL"
      },
      "source": [
        "import os\n",
        "\n",
        "BASE_DIR = '/content/drive/MyDrive/ku-ai/data'\n",
        "\n",
        "def load_data(file_name):\n",
        "    with open(os.path.join(BASE_DIR, file_name), 'r', encoding='utf-8') as fp:\n",
        "        return fp.readlines()\n",
        "\n",
        "raw_train_data = load_data('ner_train.txt')\n",
        "raw_test_data = load_data('ner_dev.txt')"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "U0Zfz_6eohhL",
        "outputId": "c7c115fb-bf1a-4f95-a041-23d60b31a0dc"
      },
      "source": [
        "tmp_data = raw_train_data[0]\n",
        "tmp_data"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'366\\t새 벽 출 조 시 <SP> 야 영 적 극 <SP> 권 장 하 ㅂ 니 다 <SP> .\\tB_TI I_TI O O O <SP> O O O O <SP> O O O O O O <SP> O\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CRMg_Co1ohhM"
      },
      "source": [
        "## Feature 로드\n",
        "\n",
        "```\n",
        "{형태소: 161차원 vector}\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vnjwzVIIohhM",
        "outputId": "b5c61d0d-85ac-4af2-e689-2795b6977701"
      },
      "source": [
        "import joblib\n",
        "\n",
        "train_feature = joblib.load(os.path.join(BASE_DIR, 'train_concat_features'))\n",
        "test_feature = joblib.load(os.path.join(BASE_DIR, 'dev_concat_features'))\n",
        "\n",
        "train_feature['새벽'].shape"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(184,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "YVcwZ8LoohhM"
      },
      "source": [
        "## 통합 데이터셋 만들기\n",
        "\n",
        "```\n",
        "{형태소: 161차원 vector}\n",
        "```\n",
        "\n",
        "Input: 음절단위 문장\n",
        "\n",
        "1. 합친다\n",
        "2. 형태소로짼다\n",
        "3. 아까했던 헝태소: 벡터 를 (길이) 만큼 한다\n",
        "4. 그러면 (seq_len, 161) 의 벡터가 데이터 크기만큼 나온다.\n",
        "5. <SOS\\> 벡터, <EOS\\> 벡터, <PAD\\> 벡터를 준다.\n",
        "6. ?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oKKmVKJzohhN",
        "outputId": "266a82bf-11f6-4a5c-f9b0-f9903e26d4d6"
      },
      "source": [
        "train_morph_token = joblib.load(os.path.join(BASE_DIR, 'train_morph_token'))\n",
        "train_pos_token = joblib.load(os.path.join(BASE_DIR, 'train_pos_token'))\n",
        "\n",
        "test_morph_token = joblib.load(os.path.join(BASE_DIR, 'test_morph_token'))\n",
        "test_pos_token = joblib.load(os.path.join(BASE_DIR, 'test_pos_token'))\n",
        "\n",
        "print(train_morph_token[0])\n",
        "print(train_pos_token[0])\n",
        "print(test_morph_token[0])\n",
        "print(test_pos_token[0])"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['새벽', '출조', '시', '<SP>', '야영', '적극', '<SP>', '권장', '하', 'ㅂ니다', '<SP>', '.']\n",
            "['NNG', 'NNG', 'NNG', '<SP>', 'NNG', 'NNG', '<SP>', 'NNG', 'XSV', 'EF', '<SP>', 'SF']\n",
            "['6', '일', '<SP>', '유통', '업계', '와', '<SP>', '정유', '업계', '에', '<SP>', '따르', '면', '<SP>', '‘', '이마트', '-', 'SK', '’', '<SP>', '간판', '을', '<SP>', '내걸', 'ㄴ', '<SP>', '주유소', '가', '<SP>', '올해', '<SP>', '안', '에', '<SP>', '등장', '하', 'ㄹ', '<SP>', '것', '이', '<SP>', '확실시', '되', '자', '<SP>', '이마트', '와', '<SP>', '경쟁', '관계', '에', '<SP>', '있', '는', '<SP>', '롯데마트', '<SP>', '홈플러스', '<SP>', '등', '<SP>', '다른', '<SP>', '대형', '<SP>', '마트', '도', '<SP>', '매장', '<SP>', '내', '<SP>', '주유소', '<SP>', '설립', '을', '<SP>', '위하', '아', '<SP>', '정유', '사와', '<SP>', '물밑', '에서', '<SP>', '활발', '하', '게', '<SP>', '접촉', '하', '고', '<SP>', '있', '다', '.']\n",
            "['SN', 'NNBC', '<SP>', 'NNG', 'NNG', 'JC', '<SP>', 'NNG', 'NNG', 'JKB', '<SP>', 'VV', 'EC', '<SP>', 'SY', 'NNP', 'SY', 'SL', 'SY', '<SP>', 'NNG', 'JKO', '<SP>', 'VV+ETM', 'NNG', '<SP>', 'NNG', 'JKS', '<SP>', 'NNG', '<SP>', 'NNG', 'JKB', '<SP>', 'NNG', 'XSV', 'JKO', '<SP>', 'NNB', 'JKS', '<SP>', 'NNG', 'XSV', 'EC', '<SP>', 'NNP', 'JKB', '<SP>', 'NNG', 'NNG', 'JKB', '<SP>', 'VA', 'ETM', '<SP>', 'NNP', '<SP>', 'NNP', '<SP>', 'NNG', '<SP>', 'MM', '<SP>', 'NNG', '<SP>', 'NNG', 'JX', '<SP>', 'NNG', '<SP>', 'NP', '<SP>', 'NNG', '<SP>', 'NNG', 'JKO', '<SP>', 'VV', 'EC', '<SP>', 'NNG', 'NNG', '<SP>', 'NNG', 'JKB', '<SP>', 'XR', 'XSA', 'EC', '<SP>', 'NNG', 'XSV', 'EC', '<SP>', 'VA', 'EF', 'SF']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ikg7KRtohhN"
      },
      "source": [
        "## `Dataset` 객체로 만들기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VmEgx-ATohhN"
      },
      "source": [
        "import os\n",
        "\n",
        "def convert_sentence(sentence):\n",
        "    return sentence.replace(' ', '').replace('<SP>', ' ')\n",
        "\n",
        "\n",
        "def load_tag_dict():\n",
        "    fp = open(os.path.join(BASE_DIR, 'tag_vocab.txt'), 'r')\n",
        "    tag_2_idx = {'<PAD>': 0, '<UNK>': 1}\n",
        "    idx_2_tag = {0: '<PAD>', 1: '<UNK>'}\n",
        "\n",
        "    index = len(tag_2_idx)\n",
        "    for line in tqdm(fp.readlines()):\n",
        "        tag = line.strip()\n",
        "        tag_2_idx[tag] = index\n",
        "        idx_2_tag[index] = tag\n",
        "        index += 1\n",
        "\n",
        "    return tag_2_idx, idx_2_tag"
      ],
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KlE8zQDvMNx_",
        "outputId": "ea71ca87-d516-421c-cf8d-5d75be26b556"
      },
      "source": [
        "tag_2_idx, idx_2_tag = load_tag_dict()"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 12/12 [00:00<00:00, 66488.31it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "993rt8SdohhN",
        "outputId": "3247703f-38f3-4c56-e702-02ced0b32f5d"
      },
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "PAD_TOKEN = 0\n",
        "UNK_TOKEN = 1\n",
        "SP_TOKEN = 2\n",
        "\n",
        "FEATURE_SIZE = 184\n",
        "\n",
        "UNK_VECTOR = [UNK_TOKEN] * FEATURE_SIZE\n",
        "SP_VECTOR = [SP_TOKEN] * FEATURE_SIZE\n",
        "PAD_VECTOR = [PAD_TOKEN] * FEATURE_SIZE\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "\n",
        "class NERDataset(Dataset):\n",
        "    def __init__(self, raw_data, morphs_list, pos_list, feature=None, device='cpu'):\n",
        "        super(NERDataset, self).__init__()\n",
        "        self.source_list = []\n",
        "        self.target_list = []\n",
        "\n",
        "        tag_dict = tag_2_idx\n",
        "        max_length = self._get_max_length(raw_data)\n",
        "\n",
        "        for row, morphs, pos in tqdm(zip(raw_data, morphs_list, pos_list)):\n",
        "            index, syllables, tags = row.rstrip('\\n').split('\\t')\n",
        "            syllables_list = syllables.split()\n",
        "            tags_list = tags.split()\n",
        "\n",
        "            encoded_syllable_list = []\n",
        "            if feature:\n",
        "                for morph in morphs:\n",
        "                    if morph in feature.keys():\n",
        "                        morph_size = len(morph) if morph != '<SP>' else 1\n",
        "                        encoded_syllable_list += [feature[morph]] * morph_size\n",
        "                    else:\n",
        "                        encoded_syllable_list += [UNK_VECTOR] * len(morph)\n",
        "\n",
        "                padding_size = max_length - len(encoded_syllable_list)\n",
        "                encoded_syllable_list += [PAD_VECTOR] * padding_size\n",
        "\n",
        "                self.source_list.append(encoded_syllable_list)\n",
        "            else:\n",
        "                # TODO: raw feature generation\n",
        "                pass\n",
        "\n",
        "            encoded_tag_list = []\n",
        "            for tag in tags_list:\n",
        "                if tag in tag_dict.keys():\n",
        "                    encoded_tag_list.append(tag_dict[tag])\n",
        "                else:\n",
        "                    encoded_tag_list.append(tag_dict['<UNK>'])\n",
        "\n",
        "            padding_size = max_length - len(encoded_tag_list)\n",
        "            encoded_tag_list += [tag_dict['<PAD>']] * padding_size\n",
        "\n",
        "            self.target_list.append(encoded_tag_list)\n",
        "\n",
        "        self.source = torch.tensor(self.source_list).to(device)\n",
        "        self.target = torch.tensor(self.target_list).to(device)\n",
        "\n",
        "    def _get_max_length(self, raw_data):\n",
        "        max_length = 0\n",
        "        for row in raw_data:\n",
        "            index, syllables, tags = row.rstrip('\\n').split('\\t')\n",
        "            syllables_list = syllables.split()\n",
        "            length = len(syllables_list)\n",
        "            if max_length < length:\n",
        "                max_length = length\n",
        "        return max_length\n",
        "\n",
        "    def __str__(self):\n",
        "        return 'source: {}, target: {}'.format(self.source.shape, self.target.shape)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.source)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return {\n",
        "            'source': self.source[idx],\n",
        "            'target': self.target[idx],\n",
        "        }\n",
        "\n",
        "\n",
        "print()\n",
        "\n",
        "train_dataset = NERDataset(raw_train_data, train_morph_token, train_pos_token, train_feature, device=device)\n",
        "test_dataset = NERDataset(raw_test_data, test_morph_token, test_pos_token, test_feature, device=device)\n",
        "\n",
        "print(train_dataset)\n",
        "print(test_dataset)\n"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2009it [00:00, 20080.83it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "7319it [00:00, 10134.08it/s]\n",
            "995it [00:00, 14157.78it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "source: torch.Size([7319, 491, 184]), target: torch.Size([7319, 491])\n",
            "source: torch.Size([995, 220, 184]), target: torch.Size([995, 220])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y1JvWfFUvOlC"
      },
      "source": [
        "joblib.dump(train_dataset, 'train_dataset')\n",
        "joblib.dump(test_dataset, 'test_dataset')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G7TG9nM2ohhN",
        "outputId": "e298f852-0538-4e84-aa72-dd02389c40a1"
      },
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "print('total steps: {}'.format(len(train_loader)), end='\\n\\n')\n",
        "\n",
        "sample = next(iter(train_loader))\n",
        "print('shape of {}: {}'.format('source', sample['source'].shape))\n",
        "print('shape of {}: {}'.format('target', sample['target'].shape), end='\\n\\n')"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total steps: 115\n",
            "\n",
            "shape of source: torch.Size([64, 491, 184])\n",
            "shape of target: torch.Size([64, 491])\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "5-AeDvqnohhN"
      },
      "source": [
        "## 모델링"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d1exnmk-v67l",
        "outputId": "30cd673b-586a-4444-ccc7-43619e425638"
      },
      "source": [
        "!pip install pytorch-crf"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pytorch-crf\n",
            "  Downloading https://files.pythonhosted.org/packages/96/7d/4c4688e26ea015fc118a0327e5726e6596836abce9182d3738be8ec2e32a/pytorch_crf-0.7.2-py3-none-any.whl\n",
            "Installing collected packages: pytorch-crf\n",
            "Successfully installed pytorch-crf-0.7.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "6y0ArDr0ohhN"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchcrf import CRF\n",
        "\n",
        "\n",
        "class RNN_CRF(nn.Module):\n",
        "    def __init__(self, pretrained_weight, embedding_size, hidden_size, output_size, dropout=0.5):\n",
        "        super(RNN_CRF, self).__init__()\n",
        "\n",
        "        # self.embedding = nn.Embedding.from_pretrained(pretrained_weight)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "        self.rnn = nn.GRU(\n",
        "            embedding_size,\n",
        "            hidden_size,\n",
        "            batch_first=True,\n",
        "            bidirectional=True\n",
        "        )\n",
        "\n",
        "        # CRF layer\n",
        "        self.crf = CRF(output_size, batch_first=True)\n",
        "\n",
        "        # (batch_size, seq_len, hidden_size * 2) -> (batch_size, seq_len, output_size)\n",
        "        self.fc = nn.Linear(hidden_size * 2, output_size)\n",
        "\n",
        "    def forward(self, inputs, labels=None):\n",
        "        # (batch_size, seq_len) -> (batch_size, seq_len, embedding_size)\n",
        "        inputs = inputs.float()\n",
        "        outputs, hidden = self.rnn(inputs)\n",
        "\n",
        "        # (batch_size, seq_len, hidden_size * 2)\n",
        "        outputs = self.dropout(outputs)\n",
        "\n",
        "        # (batch_size, seq_len, hidden_size * 2) -> (batch_size, seq_len, output_size)\n",
        "        logits = self.fc(outputs)\n",
        "\n",
        "        if labels is not None:\n",
        "            log_likelihood = self.crf(\n",
        "                emissions=logits,\n",
        "                tags=labels,\n",
        "                reduction=\"mean\"\n",
        "            )\n",
        "            loss = log_likelihood * -1.0\n",
        "            return loss\n",
        "        else:\n",
        "            output = self.crf.decode(emissions=logits)\n",
        "            return output"
      ],
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "cgRdZusMohhN"
      },
      "source": [
        "## Train and Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S5DR4udP_fL1",
        "outputId": "7962fd96-db14-43e5-a2dc-12df9c586cdb"
      },
      "source": [
        "!pip install seqeval"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting seqeval\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9d/2d/233c79d5b4e5ab1dbf111242299153f3caddddbb691219f363ad55ce783d/seqeval-1.2.2.tar.gz (43kB)\n",
            "\r\u001b[K     |███████▌                        | 10kB 22.2MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 20kB 29.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 30kB 34.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 40kB 36.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 51kB 8.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from seqeval) (1.18.5)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.6/dist-packages (from seqeval) (0.22.2.post1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.21.3->seqeval) (0.17.0)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.4.1)\n",
            "Building wheels for collected packages: seqeval\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-cp36-none-any.whl size=16171 sha256=0d2a82c0ea7846ca1acd00f5ac82b2b4af8ff7f5e3addcc383a9eb9288bec644\n",
            "  Stored in directory: /root/.cache/pip/wheels/52/df/1b/45d75646c37428f7e626214704a0e35bd3cfc32eda37e59e5f\n",
            "Successfully built seqeval\n",
            "Installing collected packages: seqeval\n",
            "Successfully installed seqeval-1.2.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hfU3OtlIohhN"
      },
      "source": [
        "import torch\n",
        "import torch.optim as optim\n",
        "from seqeval.metrics import classification_report\n",
        "\n",
        "\n",
        "def train(model, train_data, test_data=None, num_epochs=20):\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.005)\n",
        "    accuracy_list = []\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        losses = []\n",
        "\n",
        "        for step, batch in enumerate(train_data):\n",
        "            source = batch['source']\n",
        "            target = batch['target']\n",
        "            \n",
        "            loss = model.forward(source, target)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            if (step + 1) % 50 == 0:\n",
        "                print('{} step processed.. current loss : {}'.format(step + 1, loss.data.item()))\n",
        "            losses.append(loss.data.item())\n",
        "\n",
        "        print('Average Loss : {}'.format(np.mean(losses)))\n",
        "\n",
        "        torch.save(model, 'savepoint.model')\n",
        "        do_test(model, test_data)\n",
        "\n",
        "\n",
        "def tensor2list(input_tensor):\n",
        "    return input_tensor.cpu().detach().numpy().tolist()\n",
        "\n",
        "\n",
        "def do_test(model, test_dataloader):\n",
        "    model.eval()\n",
        "    \n",
        "    idx2tag = idx_2_tag\n",
        "\n",
        "    predicts, answers = [], []\n",
        "    \n",
        "    for step, batch in enumerate(test_dataloader):\n",
        "        source = batch['source']\n",
        "        target = batch['target']\n",
        "\n",
        "        # 예측 라벨 출력\n",
        "        output = model(source)\n",
        "\n",
        "        # 성능 평가를 위해 예측 값과 정답 값 리스트에 저장\n",
        "        for idx, answer in enumerate(tensor2list(target)):\n",
        "            answers.extend([idx2tag[e].replace(\"_\", \"-\") for e in answer if idx2tag[e] != \"<SP>\" and idx2tag[e] != \"<PAD>\"])\n",
        "            predicts.extend([idx2tag[e].replace(\"_\", \"-\") for i, e in enumerate(output[idx]) if idx2tag[answer[i]] != \"<SP>\" and idx2tag[answer[i]] != \"<PAD>\"] )\n",
        "    \n",
        "    # 성능 평가\n",
        "    print(classification_report([answers], [predicts]))"
      ],
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kZjeI_jXohhN",
        "outputId": "bc07f6a4-2df7-4925-8d10-705e3454f9a6"
      },
      "source": [
        "# load glove embeddings\n",
        "import os\n",
        "import joblib\n",
        "import torch\n",
        "\n",
        "train_weights = joblib.load(os.path.join(BASE_DIR, 'train_emb_word_dict_mecab_sp.pickle'))\n",
        "dev_weights = joblib.load(os.path.join(BASE_DIR, 'dev_emb_word_dict_mecab_sp.pickle'))\n",
        "\n",
        "weights = torch.FloatTensor(list({**train_weights, **dev_weights}.values())).cuda()\n",
        "\n",
        "print(weights.shape)"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([23583, 128])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IJ_-WXHVohhN",
        "outputId": "8490c38f-3c3e-49fc-89d7-f51a819d070f"
      },
      "source": [
        "input_size = 184\n",
        "hidden_size = 128\n",
        "output_size = 14\n",
        "dropout = 0.5\n",
        "\n",
        "model = RNN_CRF(weights, input_size, hidden_size, output_size, dropout=dropout).to(device)\n",
        "print(model)\n",
        "\n",
        "train(model, train_loader, test_loader)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RNN_CRF(\n",
            "  (dropout): Dropout(p=0.5, inplace=False)\n",
            "  (rnn): GRU(184, 128, batch_first=True, bidirectional=True)\n",
            "  (crf): CRF(num_tags=14)\n",
            "  (fc): Linear(in_features=256, out_features=14, bias=True)\n",
            ")\n",
            "50 step processed.. current loss : 30.606712341308594\n",
            "100 step processed.. current loss : 18.848819732666016\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 12/12 [00:00<00:00, 24105.20it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Average Loss : 60.81177305967911\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "/usr/local/lib/python3.6/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: <PAD> seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.6/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "          DT       0.38      0.38      0.38       624\n",
            "          LC       0.08      0.02      0.03       537\n",
            "          OG       0.16      0.11      0.13       973\n",
            "        PAD>       0.00      0.00      0.00         0\n",
            "          PS       0.13      0.08      0.10       742\n",
            "          TI       0.00      0.00      0.00        95\n",
            "\n",
            "   micro avg       0.21      0.14      0.17      2971\n",
            "   macro avg       0.12      0.10      0.11      2971\n",
            "weighted avg       0.18      0.14      0.15      2971\n",
            "\n",
            "50 step processed.. current loss : 13.549484252929688\n",
            "100 step processed.. current loss : 12.394071578979492\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 12/12 [00:00<00:00, 49008.42it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Average Loss : 14.126719184543775\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "          DT       0.58      0.32      0.41       624\n",
            "          LC       0.12      0.03      0.05       537\n",
            "          OG       0.28      0.09      0.13       973\n",
            "        PAD>       0.00      0.00      0.00         0\n",
            "          PS       0.16      0.09      0.12       742\n",
            "          TI       0.05      0.02      0.03        95\n",
            "\n",
            "   micro avg       0.29      0.12      0.17      2971\n",
            "   macro avg       0.20      0.09      0.12      2971\n",
            "weighted avg       0.28      0.12      0.17      2971\n",
            "\n",
            "50 step processed.. current loss : 10.290265083312988\n",
            "100 step processed.. current loss : 9.165130615234375\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 12/12 [00:00<00:00, 17172.18it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Average Loss : 10.915502519192904\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "          DT       0.49      0.18      0.27       624\n",
            "          LC       0.14      0.01      0.03       537\n",
            "          OG       0.33      0.12      0.17       973\n",
            "        PAD>       0.00      0.00      0.00         0\n",
            "          PS       0.20      0.05      0.08       742\n",
            "          TI       0.13      0.03      0.05        95\n",
            "\n",
            "   micro avg       0.31      0.09      0.14      2971\n",
            "   macro avg       0.22      0.07      0.10      2971\n",
            "weighted avg       0.29      0.09      0.14      2971\n",
            "\n",
            "50 step processed.. current loss : 8.084041595458984\n",
            "100 step processed.. current loss : 8.659183502197266\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 12/12 [00:00<00:00, 13049.43it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Average Loss : 9.13867538700933\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "          DT       0.61      0.38      0.47       624\n",
            "          LC       0.17      0.03      0.05       537\n",
            "          OG       0.33      0.12      0.18       973\n",
            "        PAD>       0.00      0.00      0.00         0\n",
            "          PS       0.25      0.07      0.11       742\n",
            "          TI       0.08      0.01      0.02        95\n",
            "\n",
            "   micro avg       0.38      0.14      0.21      2971\n",
            "   macro avg       0.24      0.10      0.14      2971\n",
            "weighted avg       0.33      0.14      0.19      2971\n",
            "\n",
            "50 step processed.. current loss : 9.095108032226562\n",
            "100 step processed.. current loss : 8.369985580444336\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 12/12 [00:00<00:00, 7449.92it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Average Loss : 7.996606063842774\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "          DT       0.54      0.26      0.35       624\n",
            "          LC       0.22      0.06      0.09       537\n",
            "          OG       0.23      0.16      0.19       973\n",
            "        PAD>       0.00      0.00      0.00         0\n",
            "          PS       0.26      0.06      0.10       742\n",
            "          TI       0.33      0.09      0.15        95\n",
            "\n",
            "   micro avg       0.30      0.14      0.19      2971\n",
            "   macro avg       0.26      0.11      0.15      2971\n",
            "weighted avg       0.31      0.14      0.18      2971\n",
            "\n",
            "50 step processed.. current loss : 8.772522926330566\n",
            "100 step processed.. current loss : 6.259340286254883\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 12/12 [00:00<00:00, 4875.21it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Average Loss : 7.480204109523608\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "          DT       0.61      0.37      0.46       624\n",
            "          LC       0.15      0.13      0.14       537\n",
            "          OG       0.25      0.15      0.19       973\n",
            "        PAD>       0.00      0.00      0.00         0\n",
            "          PS       0.27      0.09      0.13       742\n",
            "          TI       0.45      0.16      0.23        95\n",
            "\n",
            "   micro avg       0.31      0.18      0.22      2971\n",
            "   macro avg       0.29      0.15      0.19      2971\n",
            "weighted avg       0.32      0.18      0.22      2971\n",
            "\n",
            "50 step processed.. current loss : 6.494712829589844\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8loUPVgiohhN"
      },
      "source": [
        "## Test Macro F1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1bZGoMneohhN",
        "outputId": "071aa9ea-b935-43ce-c744-fc355f61d7d9"
      },
      "source": [
        "do_test(model, test_loader)"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 12/12 [00:00<00:00, 29127.11it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "995\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "          DT       0.75      1.00      0.85    154027\n",
            "          LC       0.00      0.00      0.00       537\n",
            "          OG       0.00      0.00      0.00       973\n",
            "          PS       0.00      0.00      0.00       742\n",
            "          TI       0.00      0.00      0.00        95\n",
            "\n",
            "   micro avg       0.75      0.98      0.85    156374\n",
            "   macro avg       0.15      0.20      0.17    156374\n",
            "weighted avg       0.74      0.98      0.84    156374\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "E4BRfxXZohhN"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}